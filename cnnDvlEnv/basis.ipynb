{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CONVOLUTIONAL NEURAL NETWORK NB (CNN-First on DL)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## libraries and env configuration \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#packages from tensor flow\n",
        "import tensorflow as Tf\n",
        "\n",
        "# tensor flow for optimizing the model \n",
        "\n",
        "\n",
        "# basis packages \n",
        "import os as os \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy \n",
        "import ssl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available and used :   1\n"
          ]
        }
      ],
      "source": [
        "physicalDevice = Tf.config.experimental.list_physical_devices('GPU')\n",
        "Tf.config.experimental.set_memory_growth(physicalDevice[0], True)\n",
        "print(\"Num GPUs Available and used :  \", len(physicalDevice))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2' # Suppress TensorFlow logging (1)\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## data preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "(xTrainMnist,yTrainMnist),(xTestMnist,yTestMnist)=Tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### normalization "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xTrainMnist.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xTestMnist.max()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xTestMnist = xTestMnist.astype('float32') / 255 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### changing normalization for data train: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we normalize tghe data lessing the mean and the standar deviation to xtrain data in order to have a better performance on the training process \n",
        "\n",
        "MnistMean = xTrainMnist.mean()\n",
        "MnistStd = xTrainMnist.std()\n",
        "\n",
        "# normalize the data dividing by the sd assecuring the none zero value of the sd\n",
        "\n",
        "xTrainMnist = (xTrainMnist-MnistMean)/(MnistStd+1e-7)\n",
        "\n",
        "# also normalize the test data using mean and std from training data cause the idea is that the network doesnt know these parameters of the test set\n",
        "\n",
        "xTestMnist = (xTestMnist - MnistMean)/(MnistStd+1e-7)\n",
        "\n",
        "\"\"\" also could use : \n",
        "mean = np.mean(xTrainMnist)\n",
        "print(mean)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### split train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "xTrainMnist, xValidMnist = xTrainMnist[5000:],xTrainMnist[:5000]\n",
        "yTrainMnist, yValidMnist = yTrainMnist[5000:],yTrainMnist[:5000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "look dimension size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((50000, 28, 28), (50000,), (5000, 28, 28), (5000,))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xTrainMnist.shape, yTrainMnist.shape, xValidMnist.shape, yValidMnist.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### data argumentation for best performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datagen = Tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### see number of classes/labels in order to binarize "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.unique(yTrainMnist)) # 10 classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "####  binarizing the labels in order to use only categorical cross entropy without sparse \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "yTrainMnist = Tf.keras.utils.to_categorical(yTrainMnist)\n",
        "yTestMnist = Tf.keras.utils.to_categorical(yTestMnist)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yTrainMnist[0] # one hot encoding of the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "print(yTrainMnist[0:10]) # display the first 10 labels of the training set\n",
        "print(yTestMnist[0:10]) # display the first 10 labels of the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((50000, 28, 28), (50000,), (10000, 28, 28), (10000,))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xTrainMnist.shape, yTrainMnist.shape, xTestMnist.shape, yTestMnist.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## creating a sequential model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BasicMnistModel = Tf.keras.models.Sequential() \n",
        "# Add a Flatten layer to convert the 2D images to 1D vectors  ( transforming my 28 x 28 tensor to a 1D array ) \n",
        "BasicMnistModel.add(Tf.keras.layers.Flatten(input_shape=(28, 28))) \n",
        "BasicMnistModel.summary() # display the summary of the model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BasicMnistModel.add(Tf.keras.layers.Dense(256, activation ='relu')) # add a fully connected layer with 256 neurons and ReLU activation function     \n",
        "BasicMnistModel.add(Tf.keras.layers.Dense(128, activation ='relu')) # add a fully connected layer with 128 neurons and ReLU activation function \n",
        "BasicMnistModel.add(Tf.keras.layers.Dense(10, activation ='softmax')) # add a fully connected layer with 10 neurons and softmax activation function ( output layer )    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# proceed compiling the model \n",
        "BasicMnistModel.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics= ['accuracy']) # use Adam optimizer and sparse categorical crossentropy loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### proceding training the model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fit the model to the training data\n",
        "MnistHistory = BasicMnistModel.fit(xTrainMnist, yTrainMnist, epochs = 5 , batch_size = 32, validation_split = 0.3, validation_data=(xTestMnist, yTestMnist), verbose = 1) # fit the model to the training data with 5 epochs and a batch size of 32, using 30% of the training data for validation and displaying the progress bar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### lets see accuracy of the Mnist model : \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss, acc = BasicMnistModel.evaluate(xTestMnist, yTestMnist) # evaluate the model on the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(MnistHistory.history['loss'], label='Loss (TRAIN)')\n",
        "plt.plot(MnistHistory.history['val_loss'], label='Loss (VALIDATION)')\n",
        "plt.xlabel('EPOCHS')\n",
        "plt.ylabel('LOSS')\n",
        "plt.title('Loss per epoch')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "print(f\" error w/h noisy at the entry of the model : {loss*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(MnistHistory.history['accuracy'], label='accuracy (TRAIN)')\n",
        "plt.plot(MnistHistory.history['val_accuracy'], label='accuracy (VALIDATION)')\n",
        "plt.xlabel('EPOCHS')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('accuracy per epoch')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "print(f\"accuracy w/h noisy at the entry of the model : {acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## proceed with a class prediciton for our random sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "use a random variable to our data sample "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "id = np.random.choice(xTestMnist.shape[0], 1000, replace=False) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MnistPredictions = BasicMnistModel.predict(xTestMnist[id[0]:id[0]+1]) # make predictions on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predicted_class = np.argmax(MnistPredictions, axis=1)\n",
        "plt.imshow(xTestMnist[id[0]])\n",
        "\n",
        "print(\"predicted class:\" , predicted_class)\n",
        "print(\"rial class: \",yTestMnist[id[0]]) # display the true class of the image"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "icrGGZQg7Kb1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cnnDvlEnv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
