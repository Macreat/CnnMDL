{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CONVOLUTIONAL NEURAL NETWORK NB (CNN-First on DL)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## libraries and env configuration \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#packages from tensor flow\n",
        "import tensorflow as Tf\n",
        "\n",
        "# tensor flow for optimizing the model \n",
        "\n",
        "\n",
        "# basis packages \n",
        "import os as os \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy \n",
        "import ssl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available and used :   1\n"
          ]
        }
      ],
      "source": [
        "physicalDevice = Tf.config.experimental.list_physical_devices('GPU')\n",
        "Tf.config.experimental.set_memory_growth(physicalDevice[0], True)\n",
        "print(\"Num GPUs Available and used :  \", len(physicalDevice))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2' # Suppress TensorFlow logging (1)\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## data preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "(xTrainMnist,yTrainMnist),(xTestMnist,yTestMnist)=Tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### normalization "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xTrainMnist.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xTestMnist.max()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "xTestMnist = xTestMnist.astype('float32') / 255 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### changing normalization for data train: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' also could use : \\nmean = np.mean(xTrainMnist)\\nprint(mean)\\n'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we normalize tghe data lessing the mean and the standar deviation to xtrain data in order to have a better performance on the training process \n",
        "\n",
        "MnistMean = xTrainMnist.mean()\n",
        "MnistStd = xTrainMnist.std()\n",
        "\n",
        "# normalize the data dividing by the sd assecuring the none zero value of the sd\n",
        "\n",
        "xTrainMnist = (xTrainMnist-MnistMean)/(MnistStd+1e-7)\n",
        "\n",
        "# also normalize the test data using mean and std from training data cause the idea is that the network doesnt know these parameters of the test set\n",
        "\n",
        "xTestMnist = (xTestMnist - MnistMean)/(MnistStd+1e-7)\n",
        "\n",
        "\"\"\" also could use : \n",
        "mean = np.mean(xTrainMnist)\n",
        "print(mean)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### split train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "xTrainMnist, xValidMnist = xTrainMnist[5000:],xTrainMnist[:5000]\n",
        "yTrainMnist, yValidMnist = yTrainMnist[5000:],yTrainMnist[:5000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "look dimension size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((55000, 28, 28), (55000,), (5000, 28, 28), (5000,), (10000, 28, 28), (10000,))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xTrainMnist.shape, yTrainMnist.shape, xValidMnist.shape, yValidMnist.shape , xTestMnist.shape, yTestMnist.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### data argumentation for best performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "datagen = Tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### see number of classes/labels in order to binarize "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(np.unique(yTrainMnist)) # 10 classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "####  binarizing the labels in order to use only categorical cross entropy without sparse \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "yTrainMnist = Tf.keras.utils.to_categorical(yTrainMnist,num_classes=10)\n",
        "yTestMnist = Tf.keras.utils.to_categorical(yTestMnist, num_classes= 10)\n",
        "yValidMnist = Tf.keras.utils.to_categorical(yValidMnist, num_classes=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yTrainMnist[0] # one hot encoding of the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "print(yTrainMnist[0:10]) # display the first 10 labels of the training set\n",
        "print(yTestMnist[0:10]) # display the first 10 labels of the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((55000, 28, 28), (55000, 10), (10000, 28, 28), (10000, 10))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xTrainMnist.shape, yTrainMnist.shape, xTestMnist.shape, yTestMnist.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## creating another structure for the sequential model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "proceed to use a kernel recognition filter on every layer, besides of another techniques to avoid overfitting: \n",
        "\n",
        "- dropout\n",
        "- batch normalization \n",
        "- flatten \n",
        "- global average pooling\n",
        "- regularizacion l1 o l2\n",
        "- estructura de hyperparámetros\n",
        "- funciones de activacion \n",
        "- (PRUNNING & SPARSITY ¿?) \n",
        "    * Función: Eliminan conexiones o neuronas innecesarias en la red, reduciendo la complejidad del modelo y mejorando la eficiencia computacional.​\n",
        "\n",
        "    * Implementación: Se aplican después del entrenamiento inicial para identificar y eliminar pesos insignificantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "KernelBase = 32 \n",
        "WeightRegularizer = 1e-4 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "MnistModel = Tf.keras.models.Sequential() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "making layer by layer \n",
        "First one is a convolutional sequence of layers : \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "MnistModel.add(Tf.keras.layers.Conv2D(KernelBase, (3,3), padding = 'same', input_shape=(28,28,1), kernel_regularizer = Tf.keras.regularizers.l2(WeightRegularizer)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "once we add the first convolutional layer with 32 filters of size 3x3 and a regularization term to avoid overfitting\n",
        "proceed adding the activation function ReLU to the output of the convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "MnistModel.add(Tf.keras.layers.Activation('relu'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " finally goes with the batch normalization to normalize the output of the previous layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "MnistModel.add(Tf.keras.layers.BatchNormalization())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "also implement a maxpooling 2d layer and dropout on this another layer : \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "MnistModel.add(Tf.keras.layers.Conv2D(KernelBase, (3, 3), padding='same', activation='relu', kernel_regularizer=Tf.keras.regularizers.l2(WeightRegularizer), input_shape=(28, 28, 1)))\n",
        "MnistModel.add(Tf.keras.layers.LeakyReLU(alpha=0.1)) # we use a different activation function to see if it improves the performance of the model\n",
        "MnistModel.add(Tf.keras.layers.BatchNormalization())\n",
        "MnistModel.add(Tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')) \n",
        "MnistModel.add(Tf.keras.layers.Dropout(0.25)) # we add a dropout layer to reduce overfitting "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "now, we nee to do the last classification layer with a dense and a flatten function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add a Flatten layer to convert the 2D images to 1D vectors  (transform the img to an array)\n",
        "MnistModel.add(Tf.keras.layers.Flatten()) # without the input size "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "finally,  10 classes for the output layer with a softmax activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "MnistModel.add(Tf.keras.layers.Dense(10,activation= 'softmax'))  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "lets see a summary of the structure: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 28, 28, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                62730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 72,554\n",
            "Trainable params: 72,426\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "MnistModel.summary() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "proceed compiling the model \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "MnistModel.compile(optimizer=Tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy']) # we use adam optimizer with a learning rate of 0.001 and categorical cross entropy as loss function\n",
        "# use addam optimizer with a learning rate of 0.001 and categorical cross entropy as loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "also we can do a callback checkpoint when were we are fitting the model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "CBCheckPoint = Tf.keras.callbacks.ModelCheckpoint(\"best_model,keras\", verbose = 1, save_best_only = True, monitor = \"val_accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### proceding training the model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Asegúrate de que los datos tengan 4 dimensiones\n",
        "xTrainMnist = np.expand_dims(xTrainMnist, axis=-1)  # Agrega la dimensión del canal\n",
        "xValidMnist = np.expand_dims(xValidMnist, axis=-1)  # Agrega la dimensión del canal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.66840, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 72s - loss: 1.2227 - accuracy: 0.6190 - val_loss: 0.9820 - val_accuracy: 0.6684 - 72s/epoch - 167ms/step\n",
            "Epoch 2/1000\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.66840 to 0.80460, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 18s - loss: 0.7864 - accuracy: 0.7418 - val_loss: 0.6447 - val_accuracy: 0.8046 - 18s/epoch - 43ms/step\n",
            "Epoch 3/1000\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.80460 to 0.83920, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 18s - loss: 0.6536 - accuracy: 0.7818 - val_loss: 0.5268 - val_accuracy: 0.8392 - 18s/epoch - 43ms/step\n",
            "Epoch 4/1000\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.83920 to 0.83960, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 20s - loss: 0.5638 - accuracy: 0.8136 - val_loss: 0.5055 - val_accuracy: 0.8396 - 20s/epoch - 47ms/step\n",
            "Epoch 5/1000\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.83960 to 0.87880, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 25s - loss: 0.5122 - accuracy: 0.8297 - val_loss: 0.3733 - val_accuracy: 0.8788 - 25s/epoch - 59ms/step\n",
            "Epoch 6/1000\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.87880\n",
            "429/429 - 20s - loss: 0.4784 - accuracy: 0.8416 - val_loss: 0.3632 - val_accuracy: 0.8764 - 20s/epoch - 48ms/step\n",
            "Epoch 7/1000\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.87880\n",
            "429/429 - 19s - loss: 0.4568 - accuracy: 0.8480 - val_loss: 0.4126 - val_accuracy: 0.8702 - 19s/epoch - 45ms/step\n",
            "Epoch 8/1000\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.87880\n",
            "429/429 - 21s - loss: 0.4319 - accuracy: 0.8570 - val_loss: 0.3899 - val_accuracy: 0.8728 - 21s/epoch - 49ms/step\n",
            "Epoch 9/1000\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.87880 to 0.90080, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 34s - loss: 0.4208 - accuracy: 0.8608 - val_loss: 0.3139 - val_accuracy: 0.9008 - 34s/epoch - 79ms/step\n",
            "Epoch 10/1000\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.90080 to 0.92040, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 36s - loss: 0.4129 - accuracy: 0.8638 - val_loss: 0.2528 - val_accuracy: 0.9204 - 36s/epoch - 85ms/step\n",
            "Epoch 11/1000\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.92040\n",
            "429/429 - 21s - loss: 0.3986 - accuracy: 0.8698 - val_loss: 0.5123 - val_accuracy: 0.8360 - 21s/epoch - 49ms/step\n",
            "Epoch 12/1000\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.92040\n",
            "429/429 - 51s - loss: 0.3987 - accuracy: 0.8692 - val_loss: 0.3744 - val_accuracy: 0.8688 - 51s/epoch - 120ms/step\n",
            "Epoch 13/1000\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.92040\n",
            "429/429 - 40s - loss: 0.3888 - accuracy: 0.8734 - val_loss: 0.3060 - val_accuracy: 0.9012 - 40s/epoch - 92ms/step\n",
            "Epoch 14/1000\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.92040\n",
            "429/429 - 28s - loss: 0.3829 - accuracy: 0.8736 - val_loss: 0.2919 - val_accuracy: 0.9056 - 28s/epoch - 65ms/step\n",
            "Epoch 15/1000\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.92040\n",
            "429/429 - 22s - loss: 0.3730 - accuracy: 0.8778 - val_loss: 0.3104 - val_accuracy: 0.9030 - 22s/epoch - 52ms/step\n",
            "Epoch 16/1000\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.92040\n",
            "429/429 - 23s - loss: 0.3700 - accuracy: 0.8789 - val_loss: 0.2694 - val_accuracy: 0.9168 - 23s/epoch - 52ms/step\n",
            "Epoch 17/1000\n",
            "\n",
            "Epoch 17: val_accuracy improved from 0.92040 to 0.92340, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 24s - loss: 0.3672 - accuracy: 0.8808 - val_loss: 0.2521 - val_accuracy: 0.9234 - 24s/epoch - 57ms/step\n",
            "Epoch 18/1000\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.92340\n",
            "429/429 - 22s - loss: 0.3627 - accuracy: 0.8826 - val_loss: 0.2737 - val_accuracy: 0.9138 - 22s/epoch - 52ms/step\n",
            "Epoch 19/1000\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.92340\n",
            "429/429 - 22s - loss: 0.3602 - accuracy: 0.8813 - val_loss: 0.3797 - val_accuracy: 0.8714 - 22s/epoch - 52ms/step\n",
            "Epoch 20/1000\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.92340\n",
            "429/429 - 22s - loss: 0.3570 - accuracy: 0.8847 - val_loss: 0.2715 - val_accuracy: 0.9062 - 22s/epoch - 50ms/step\n",
            "Epoch 21/1000\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.92340\n",
            "429/429 - 23s - loss: 0.3545 - accuracy: 0.8844 - val_loss: 0.2576 - val_accuracy: 0.9172 - 23s/epoch - 53ms/step\n",
            "Epoch 22/1000\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.92340\n",
            "429/429 - 24s - loss: 0.3495 - accuracy: 0.8864 - val_loss: 0.2842 - val_accuracy: 0.9156 - 24s/epoch - 57ms/step\n",
            "Epoch 23/1000\n",
            "\n",
            "Epoch 23: val_accuracy improved from 0.92340 to 0.92560, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 26s - loss: 0.3423 - accuracy: 0.8894 - val_loss: 0.2415 - val_accuracy: 0.9256 - 26s/epoch - 59ms/step\n",
            "Epoch 24/1000\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.92560\n",
            "429/429 - 24s - loss: 0.3440 - accuracy: 0.8882 - val_loss: 0.2945 - val_accuracy: 0.9026 - 24s/epoch - 56ms/step\n",
            "Epoch 25/1000\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.92560\n",
            "429/429 - 24s - loss: 0.3376 - accuracy: 0.8899 - val_loss: 0.2461 - val_accuracy: 0.9252 - 24s/epoch - 57ms/step\n",
            "Epoch 26/1000\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.92560\n",
            "429/429 - 29s - loss: 0.3378 - accuracy: 0.8889 - val_loss: 0.2587 - val_accuracy: 0.9150 - 29s/epoch - 67ms/step\n",
            "Epoch 27/1000\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.92560\n",
            "429/429 - 24s - loss: 0.3375 - accuracy: 0.8912 - val_loss: 0.2538 - val_accuracy: 0.9168 - 24s/epoch - 57ms/step\n",
            "Epoch 28/1000\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.92560\n",
            "429/429 - 22s - loss: 0.3398 - accuracy: 0.8904 - val_loss: 0.2407 - val_accuracy: 0.9206 - 22s/epoch - 50ms/step\n",
            "Epoch 29/1000\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.92560\n",
            "429/429 - 21s - loss: 0.3335 - accuracy: 0.8915 - val_loss: 0.2481 - val_accuracy: 0.9244 - 21s/epoch - 48ms/step\n",
            "Epoch 30/1000\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.92560\n",
            "429/429 - 21s - loss: 0.3287 - accuracy: 0.8936 - val_loss: 0.2509 - val_accuracy: 0.9216 - 21s/epoch - 48ms/step\n",
            "Epoch 31/1000\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.92560\n",
            "429/429 - 20s - loss: 0.3276 - accuracy: 0.8928 - val_loss: 0.2579 - val_accuracy: 0.9152 - 20s/epoch - 47ms/step\n",
            "Epoch 32/1000\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.92560\n",
            "429/429 - 22s - loss: 0.3267 - accuracy: 0.8955 - val_loss: 0.2863 - val_accuracy: 0.9024 - 22s/epoch - 52ms/step\n",
            "Epoch 33/1000\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.92560\n",
            "429/429 - 21s - loss: 0.3262 - accuracy: 0.8954 - val_loss: 0.2626 - val_accuracy: 0.9158 - 21s/epoch - 48ms/step\n",
            "Epoch 34/1000\n",
            "\n",
            "Epoch 34: val_accuracy improved from 0.92560 to 0.93680, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 23s - loss: 0.3218 - accuracy: 0.8959 - val_loss: 0.2107 - val_accuracy: 0.9368 - 23s/epoch - 53ms/step\n",
            "Epoch 35/1000\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.93680\n",
            "429/429 - 23s - loss: 0.3226 - accuracy: 0.8961 - val_loss: 0.2723 - val_accuracy: 0.9078 - 23s/epoch - 53ms/step\n",
            "Epoch 36/1000\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.93680\n",
            "429/429 - 21s - loss: 0.3285 - accuracy: 0.8922 - val_loss: 0.2594 - val_accuracy: 0.9182 - 21s/epoch - 49ms/step\n",
            "Epoch 37/1000\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.93680\n",
            "429/429 - 20s - loss: 0.3217 - accuracy: 0.8967 - val_loss: 0.2354 - val_accuracy: 0.9254 - 20s/epoch - 46ms/step\n",
            "Epoch 38/1000\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.93680\n",
            "429/429 - 20s - loss: 0.3217 - accuracy: 0.8954 - val_loss: 0.2521 - val_accuracy: 0.9184 - 20s/epoch - 46ms/step\n",
            "Epoch 39/1000\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.93680\n",
            "429/429 - 20s - loss: 0.3179 - accuracy: 0.8990 - val_loss: 0.2442 - val_accuracy: 0.9218 - 20s/epoch - 47ms/step\n",
            "Epoch 40/1000\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.93680\n",
            "429/429 - 22s - loss: 0.3198 - accuracy: 0.8966 - val_loss: 0.2329 - val_accuracy: 0.9220 - 22s/epoch - 52ms/step\n",
            "Epoch 41/1000\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.93680\n",
            "429/429 - 28s - loss: 0.3160 - accuracy: 0.8981 - val_loss: 0.2882 - val_accuracy: 0.9084 - 28s/epoch - 64ms/step\n",
            "Epoch 42/1000\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.93680\n",
            "429/429 - 23s - loss: 0.3178 - accuracy: 0.8983 - val_loss: 0.2279 - val_accuracy: 0.9282 - 23s/epoch - 54ms/step\n",
            "Epoch 43/1000\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.93680\n",
            "429/429 - 20s - loss: 0.3147 - accuracy: 0.8996 - val_loss: 0.2600 - val_accuracy: 0.9146 - 20s/epoch - 47ms/step\n",
            "Epoch 44/1000\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.93680\n",
            "429/429 - 23s - loss: 0.3213 - accuracy: 0.8978 - val_loss: 0.2394 - val_accuracy: 0.9250 - 23s/epoch - 53ms/step\n",
            "Epoch 45/1000\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.93680\n",
            "429/429 - 23s - loss: 0.3110 - accuracy: 0.9000 - val_loss: 0.2280 - val_accuracy: 0.9284 - 23s/epoch - 53ms/step\n",
            "Epoch 46/1000\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.93680\n",
            "429/429 - 22s - loss: 0.3143 - accuracy: 0.8998 - val_loss: 0.2564 - val_accuracy: 0.9178 - 22s/epoch - 51ms/step\n",
            "Epoch 47/1000\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.93680\n",
            "429/429 - 22s - loss: 0.3101 - accuracy: 0.9012 - val_loss: 0.2152 - val_accuracy: 0.9342 - 22s/epoch - 52ms/step\n",
            "Epoch 48/1000\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.93680\n",
            "429/429 - 22s - loss: 0.3115 - accuracy: 0.9003 - val_loss: 0.2377 - val_accuracy: 0.9222 - 22s/epoch - 52ms/step\n",
            "Epoch 49/1000\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.93680\n",
            "429/429 - 22s - loss: 0.3123 - accuracy: 0.9000 - val_loss: 0.2450 - val_accuracy: 0.9250 - 22s/epoch - 51ms/step\n",
            "Epoch 50/1000\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.93680\n",
            "429/429 - 23s - loss: 0.3120 - accuracy: 0.9002 - val_loss: 0.2372 - val_accuracy: 0.9276 - 23s/epoch - 53ms/step\n",
            "Epoch 51/1000\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.93680\n",
            "429/429 - 22s - loss: 0.3057 - accuracy: 0.9027 - val_loss: 0.2308 - val_accuracy: 0.9250 - 22s/epoch - 51ms/step\n",
            "Epoch 52/1000\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.93680\n",
            "429/429 - 23s - loss: 0.3120 - accuracy: 0.8998 - val_loss: 0.2219 - val_accuracy: 0.9298 - 23s/epoch - 54ms/step\n",
            "Epoch 53/1000\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.93680\n",
            "429/429 - 21s - loss: 0.3067 - accuracy: 0.9039 - val_loss: 0.2507 - val_accuracy: 0.9196 - 21s/epoch - 48ms/step\n",
            "Epoch 54/1000\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.93680\n",
            "429/429 - 20s - loss: 0.3044 - accuracy: 0.9040 - val_loss: 0.2575 - val_accuracy: 0.9156 - 20s/epoch - 46ms/step\n",
            "Epoch 55/1000\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.93680\n",
            "429/429 - 21s - loss: 0.3013 - accuracy: 0.9042 - val_loss: 0.2313 - val_accuracy: 0.9290 - 21s/epoch - 48ms/step\n",
            "Epoch 56/1000\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.93680\n",
            "429/429 - 20s - loss: 0.3065 - accuracy: 0.9026 - val_loss: 0.2495 - val_accuracy: 0.9174 - 20s/epoch - 46ms/step\n",
            "Epoch 57/1000\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.93680\n",
            "429/429 - 19s - loss: 0.3041 - accuracy: 0.9027 - val_loss: 0.3469 - val_accuracy: 0.8906 - 19s/epoch - 44ms/step\n",
            "Epoch 58/1000\n",
            "\n",
            "Epoch 58: val_accuracy improved from 0.93680 to 0.93720, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 22s - loss: 0.3064 - accuracy: 0.9023 - val_loss: 0.2058 - val_accuracy: 0.9372 - 22s/epoch - 50ms/step\n",
            "Epoch 59/1000\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.93720\n",
            "429/429 - 19s - loss: 0.3044 - accuracy: 0.9031 - val_loss: 0.2247 - val_accuracy: 0.9290 - 19s/epoch - 43ms/step\n",
            "Epoch 60/1000\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.93720\n",
            "429/429 - 19s - loss: 0.2986 - accuracy: 0.9050 - val_loss: 0.2201 - val_accuracy: 0.9352 - 19s/epoch - 44ms/step\n",
            "Epoch 61/1000\n",
            "\n",
            "Epoch 61: val_accuracy improved from 0.93720 to 0.93880, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 20s - loss: 0.2999 - accuracy: 0.9044 - val_loss: 0.2004 - val_accuracy: 0.9388 - 20s/epoch - 46ms/step\n",
            "Epoch 62/1000\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.93880\n",
            "429/429 - 22s - loss: 0.3009 - accuracy: 0.9046 - val_loss: 0.2252 - val_accuracy: 0.9312 - 22s/epoch - 52ms/step\n",
            "Epoch 63/1000\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.93880\n",
            "429/429 - 21s - loss: 0.3006 - accuracy: 0.9032 - val_loss: 0.2263 - val_accuracy: 0.9290 - 21s/epoch - 48ms/step\n",
            "Epoch 64/1000\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.93880\n",
            "429/429 - 20s - loss: 0.2982 - accuracy: 0.9065 - val_loss: 0.2289 - val_accuracy: 0.9290 - 20s/epoch - 47ms/step\n",
            "Epoch 65/1000\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 0.93880\n",
            "429/429 - 21s - loss: 0.2999 - accuracy: 0.9051 - val_loss: 0.2495 - val_accuracy: 0.9256 - 21s/epoch - 48ms/step\n",
            "Epoch 66/1000\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.93880\n",
            "429/429 - 21s - loss: 0.2975 - accuracy: 0.9053 - val_loss: 0.2221 - val_accuracy: 0.9334 - 21s/epoch - 48ms/step\n",
            "Epoch 67/1000\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.93880\n",
            "429/429 - 20s - loss: 0.3012 - accuracy: 0.9062 - val_loss: 0.2084 - val_accuracy: 0.9366 - 20s/epoch - 47ms/step\n",
            "Epoch 68/1000\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.93880\n",
            "429/429 - 21s - loss: 0.2949 - accuracy: 0.9062 - val_loss: 0.2253 - val_accuracy: 0.9300 - 21s/epoch - 50ms/step\n",
            "Epoch 69/1000\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.93880\n",
            "429/429 - 21s - loss: 0.2960 - accuracy: 0.9055 - val_loss: 0.2252 - val_accuracy: 0.9318 - 21s/epoch - 49ms/step\n",
            "Epoch 70/1000\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.93880\n",
            "429/429 - 20s - loss: 0.2958 - accuracy: 0.9074 - val_loss: 0.2300 - val_accuracy: 0.9278 - 20s/epoch - 47ms/step\n",
            "Epoch 71/1000\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.93880\n",
            "429/429 - 21s - loss: 0.2963 - accuracy: 0.9056 - val_loss: 0.2049 - val_accuracy: 0.9382 - 21s/epoch - 49ms/step\n",
            "Epoch 72/1000\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 0.93880\n",
            "429/429 - 19s - loss: 0.2980 - accuracy: 0.9071 - val_loss: 0.2779 - val_accuracy: 0.9140 - 19s/epoch - 45ms/step\n",
            "Epoch 73/1000\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 0.93880\n",
            "429/429 - 19s - loss: 0.2938 - accuracy: 0.9070 - val_loss: 0.2531 - val_accuracy: 0.9220 - 19s/epoch - 44ms/step\n",
            "Epoch 74/1000\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.93880\n",
            "429/429 - 19s - loss: 0.2957 - accuracy: 0.9069 - val_loss: 0.2322 - val_accuracy: 0.9268 - 19s/epoch - 44ms/step\n",
            "Epoch 75/1000\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.93880\n",
            "429/429 - 18s - loss: 0.2930 - accuracy: 0.9064 - val_loss: 0.2832 - val_accuracy: 0.9084 - 18s/epoch - 43ms/step\n",
            "Epoch 76/1000\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.93880\n",
            "429/429 - 21s - loss: 0.2954 - accuracy: 0.9068 - val_loss: 0.2216 - val_accuracy: 0.9342 - 21s/epoch - 49ms/step\n",
            "Epoch 77/1000\n",
            "\n",
            "Epoch 77: val_accuracy improved from 0.93880 to 0.94140, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 21s - loss: 0.2914 - accuracy: 0.9080 - val_loss: 0.2059 - val_accuracy: 0.9414 - 21s/epoch - 49ms/step\n",
            "Epoch 78/1000\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.94140\n",
            "429/429 - 19s - loss: 0.2930 - accuracy: 0.9069 - val_loss: 0.2327 - val_accuracy: 0.9314 - 19s/epoch - 45ms/step\n",
            "Epoch 79/1000\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.94140\n",
            "429/429 - 20s - loss: 0.2913 - accuracy: 0.9085 - val_loss: 0.2064 - val_accuracy: 0.9406 - 20s/epoch - 47ms/step\n",
            "Epoch 80/1000\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.94140\n",
            "429/429 - 19s - loss: 0.2949 - accuracy: 0.9074 - val_loss: 0.2176 - val_accuracy: 0.9298 - 19s/epoch - 45ms/step\n",
            "Epoch 81/1000\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.94140\n",
            "429/429 - 19s - loss: 0.2863 - accuracy: 0.9084 - val_loss: 0.2324 - val_accuracy: 0.9314 - 19s/epoch - 45ms/step\n",
            "Epoch 82/1000\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.94140\n",
            "429/429 - 19s - loss: 0.2946 - accuracy: 0.9068 - val_loss: 0.2192 - val_accuracy: 0.9324 - 19s/epoch - 45ms/step\n",
            "Epoch 83/1000\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.94140\n",
            "429/429 - 21s - loss: 0.2886 - accuracy: 0.9084 - val_loss: 0.2343 - val_accuracy: 0.9286 - 21s/epoch - 49ms/step\n",
            "Epoch 84/1000\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.94140\n",
            "429/429 - 20s - loss: 0.2889 - accuracy: 0.9091 - val_loss: 0.2343 - val_accuracy: 0.9222 - 20s/epoch - 46ms/step\n",
            "Epoch 85/1000\n",
            "\n",
            "Epoch 85: val_accuracy improved from 0.94140 to 0.94280, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 23s - loss: 0.2926 - accuracy: 0.9078 - val_loss: 0.1889 - val_accuracy: 0.9428 - 23s/epoch - 54ms/step\n",
            "Epoch 86/1000\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.94280\n",
            "429/429 - 22s - loss: 0.2867 - accuracy: 0.9084 - val_loss: 0.2002 - val_accuracy: 0.9418 - 22s/epoch - 52ms/step\n",
            "Epoch 87/1000\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.94280\n",
            "429/429 - 21s - loss: 0.2939 - accuracy: 0.9076 - val_loss: 0.2620 - val_accuracy: 0.9182 - 21s/epoch - 48ms/step\n",
            "Epoch 88/1000\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.94280\n",
            "429/429 - 21s - loss: 0.2898 - accuracy: 0.9089 - val_loss: 0.2277 - val_accuracy: 0.9296 - 21s/epoch - 49ms/step\n",
            "Epoch 89/1000\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.94280\n",
            "429/429 - 21s - loss: 0.2878 - accuracy: 0.9098 - val_loss: 0.1890 - val_accuracy: 0.9424 - 21s/epoch - 49ms/step\n",
            "Epoch 90/1000\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.94280\n",
            "429/429 - 21s - loss: 0.2844 - accuracy: 0.9094 - val_loss: 0.2007 - val_accuracy: 0.9394 - 21s/epoch - 49ms/step\n",
            "Epoch 91/1000\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.94280\n",
            "429/429 - 22s - loss: 0.2841 - accuracy: 0.9108 - val_loss: 0.2267 - val_accuracy: 0.9256 - 22s/epoch - 50ms/step\n",
            "Epoch 92/1000\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.94280\n",
            "429/429 - 21s - loss: 0.2909 - accuracy: 0.9082 - val_loss: 0.1993 - val_accuracy: 0.9400 - 21s/epoch - 49ms/step\n",
            "Epoch 93/1000\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.94280\n",
            "429/429 - 22s - loss: 0.2862 - accuracy: 0.9078 - val_loss: 0.2111 - val_accuracy: 0.9374 - 22s/epoch - 51ms/step\n",
            "Epoch 94/1000\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.94280\n",
            "429/429 - 22s - loss: 0.2868 - accuracy: 0.9094 - val_loss: 0.2103 - val_accuracy: 0.9350 - 22s/epoch - 50ms/step\n",
            "Epoch 95/1000\n",
            "\n",
            "Epoch 95: val_accuracy improved from 0.94280 to 0.94580, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 23s - loss: 0.2893 - accuracy: 0.9084 - val_loss: 0.1911 - val_accuracy: 0.9458 - 23s/epoch - 54ms/step\n",
            "Epoch 96/1000\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.94580\n",
            "429/429 - 23s - loss: 0.2854 - accuracy: 0.9103 - val_loss: 0.2078 - val_accuracy: 0.9366 - 23s/epoch - 54ms/step\n",
            "Epoch 97/1000\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.94580\n",
            "429/429 - 24s - loss: 0.2895 - accuracy: 0.9081 - val_loss: 0.2484 - val_accuracy: 0.9230 - 24s/epoch - 56ms/step\n",
            "Epoch 98/1000\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.94580\n",
            "429/429 - 21s - loss: 0.2900 - accuracy: 0.9081 - val_loss: 0.2274 - val_accuracy: 0.9332 - 21s/epoch - 50ms/step\n",
            "Epoch 99/1000\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.94580\n",
            "429/429 - 20s - loss: 0.2879 - accuracy: 0.9089 - val_loss: 0.2438 - val_accuracy: 0.9204 - 20s/epoch - 46ms/step\n",
            "Epoch 100/1000\n",
            "\n",
            "Epoch 100: val_accuracy improved from 0.94580 to 0.95000, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 21s - loss: 0.2884 - accuracy: 0.9093 - val_loss: 0.1876 - val_accuracy: 0.9500 - 21s/epoch - 49ms/step\n",
            "Epoch 101/1000\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2855 - accuracy: 0.9110 - val_loss: 0.2145 - val_accuracy: 0.9412 - 20s/epoch - 47ms/step\n",
            "Epoch 102/1000\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2844 - accuracy: 0.9096 - val_loss: 0.2160 - val_accuracy: 0.9382 - 20s/epoch - 47ms/step\n",
            "Epoch 103/1000\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.95000\n",
            "429/429 - 21s - loss: 0.2896 - accuracy: 0.9085 - val_loss: 0.2232 - val_accuracy: 0.9286 - 21s/epoch - 48ms/step\n",
            "Epoch 104/1000\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2851 - accuracy: 0.9108 - val_loss: 0.2270 - val_accuracy: 0.9304 - 20s/epoch - 47ms/step\n",
            "Epoch 105/1000\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2806 - accuracy: 0.9114 - val_loss: 0.2071 - val_accuracy: 0.9366 - 20s/epoch - 47ms/step\n",
            "Epoch 106/1000\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.95000\n",
            "429/429 - 21s - loss: 0.2854 - accuracy: 0.9104 - val_loss: 0.2321 - val_accuracy: 0.9270 - 21s/epoch - 48ms/step\n",
            "Epoch 107/1000\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.95000\n",
            "429/429 - 21s - loss: 0.2834 - accuracy: 0.9115 - val_loss: 0.2329 - val_accuracy: 0.9264 - 21s/epoch - 49ms/step\n",
            "Epoch 108/1000\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.95000\n",
            "429/429 - 21s - loss: 0.2854 - accuracy: 0.9109 - val_loss: 0.2357 - val_accuracy: 0.9240 - 21s/epoch - 50ms/step\n",
            "Epoch 109/1000\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.95000\n",
            "429/429 - 22s - loss: 0.2790 - accuracy: 0.9131 - val_loss: 0.2603 - val_accuracy: 0.9150 - 22s/epoch - 51ms/step\n",
            "Epoch 110/1000\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2844 - accuracy: 0.9109 - val_loss: 0.2285 - val_accuracy: 0.9310 - 19s/epoch - 44ms/step\n",
            "Epoch 111/1000\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2808 - accuracy: 0.9127 - val_loss: 0.2004 - val_accuracy: 0.9440 - 19s/epoch - 45ms/step\n",
            "Epoch 112/1000\n",
            "\n",
            "Epoch 112: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2809 - accuracy: 0.9118 - val_loss: 0.2395 - val_accuracy: 0.9280 - 19s/epoch - 43ms/step\n",
            "Epoch 113/1000\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2790 - accuracy: 0.9123 - val_loss: 0.2185 - val_accuracy: 0.9302 - 18s/epoch - 43ms/step\n",
            "Epoch 114/1000\n",
            "\n",
            "Epoch 114: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2824 - accuracy: 0.9114 - val_loss: 0.2119 - val_accuracy: 0.9348 - 18s/epoch - 42ms/step\n",
            "Epoch 115/1000\n",
            "\n",
            "Epoch 115: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2778 - accuracy: 0.9129 - val_loss: 0.2346 - val_accuracy: 0.9278 - 18s/epoch - 42ms/step\n",
            "Epoch 116/1000\n",
            "\n",
            "Epoch 116: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2777 - accuracy: 0.9133 - val_loss: 0.2065 - val_accuracy: 0.9360 - 18s/epoch - 43ms/step\n",
            "Epoch 117/1000\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2798 - accuracy: 0.9126 - val_loss: 0.2149 - val_accuracy: 0.9340 - 18s/epoch - 42ms/step\n",
            "Epoch 118/1000\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2838 - accuracy: 0.9114 - val_loss: 0.2099 - val_accuracy: 0.9384 - 19s/epoch - 44ms/step\n",
            "Epoch 119/1000\n",
            "\n",
            "Epoch 119: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2857 - accuracy: 0.9103 - val_loss: 0.2261 - val_accuracy: 0.9312 - 19s/epoch - 45ms/step\n",
            "Epoch 120/1000\n",
            "\n",
            "Epoch 120: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2824 - accuracy: 0.9110 - val_loss: 0.2039 - val_accuracy: 0.9404 - 19s/epoch - 44ms/step\n",
            "Epoch 121/1000\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2808 - accuracy: 0.9122 - val_loss: 0.2038 - val_accuracy: 0.9380 - 19s/epoch - 45ms/step\n",
            "Epoch 122/1000\n",
            "\n",
            "Epoch 122: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2830 - accuracy: 0.9113 - val_loss: 0.1993 - val_accuracy: 0.9360 - 18s/epoch - 43ms/step\n",
            "Epoch 123/1000\n",
            "\n",
            "Epoch 123: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2810 - accuracy: 0.9129 - val_loss: 0.2137 - val_accuracy: 0.9372 - 19s/epoch - 44ms/step\n",
            "Epoch 124/1000\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2758 - accuracy: 0.9135 - val_loss: 0.2197 - val_accuracy: 0.9334 - 19s/epoch - 44ms/step\n",
            "Epoch 125/1000\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2808 - accuracy: 0.9118 - val_loss: 0.2167 - val_accuracy: 0.9310 - 19s/epoch - 45ms/step\n",
            "Epoch 126/1000\n",
            "\n",
            "Epoch 126: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2820 - accuracy: 0.9125 - val_loss: 0.2137 - val_accuracy: 0.9318 - 19s/epoch - 44ms/step\n",
            "Epoch 127/1000\n",
            "\n",
            "Epoch 127: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2837 - accuracy: 0.9112 - val_loss: 0.2205 - val_accuracy: 0.9342 - 20s/epoch - 47ms/step\n",
            "Epoch 128/1000\n",
            "\n",
            "Epoch 128: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2814 - accuracy: 0.9119 - val_loss: 0.2050 - val_accuracy: 0.9410 - 20s/epoch - 46ms/step\n",
            "Epoch 129/1000\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2808 - accuracy: 0.9121 - val_loss: 0.1986 - val_accuracy: 0.9404 - 19s/epoch - 45ms/step\n",
            "Epoch 130/1000\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2774 - accuracy: 0.9131 - val_loss: 0.2024 - val_accuracy: 0.9454 - 19s/epoch - 45ms/step\n",
            "Epoch 131/1000\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2806 - accuracy: 0.9129 - val_loss: 0.2434 - val_accuracy: 0.9266 - 20s/epoch - 46ms/step\n",
            "Epoch 132/1000\n",
            "\n",
            "Epoch 132: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2775 - accuracy: 0.9137 - val_loss: 0.1919 - val_accuracy: 0.9424 - 20s/epoch - 47ms/step\n",
            "Epoch 133/1000\n",
            "\n",
            "Epoch 133: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2795 - accuracy: 0.9125 - val_loss: 0.2182 - val_accuracy: 0.9350 - 20s/epoch - 47ms/step\n",
            "Epoch 134/1000\n",
            "\n",
            "Epoch 134: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2803 - accuracy: 0.9133 - val_loss: 0.2172 - val_accuracy: 0.9284 - 20s/epoch - 47ms/step\n",
            "Epoch 135/1000\n",
            "\n",
            "Epoch 135: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2784 - accuracy: 0.9121 - val_loss: 0.2126 - val_accuracy: 0.9370 - 20s/epoch - 48ms/step\n",
            "Epoch 136/1000\n",
            "\n",
            "Epoch 136: val_accuracy did not improve from 0.95000\n",
            "429/429 - 21s - loss: 0.2845 - accuracy: 0.9119 - val_loss: 0.2238 - val_accuracy: 0.9350 - 21s/epoch - 48ms/step\n",
            "Epoch 137/1000\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.95000\n",
            "429/429 - 21s - loss: 0.2776 - accuracy: 0.9142 - val_loss: 0.1933 - val_accuracy: 0.9456 - 21s/epoch - 50ms/step\n",
            "Epoch 138/1000\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2770 - accuracy: 0.9130 - val_loss: 0.2251 - val_accuracy: 0.9330 - 20s/epoch - 47ms/step\n",
            "Epoch 139/1000\n",
            "\n",
            "Epoch 139: val_accuracy did not improve from 0.95000\n",
            "429/429 - 22s - loss: 0.2761 - accuracy: 0.9142 - val_loss: 0.2261 - val_accuracy: 0.9330 - 22s/epoch - 52ms/step\n",
            "Epoch 140/1000\n",
            "\n",
            "Epoch 140: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2807 - accuracy: 0.9133 - val_loss: 0.1891 - val_accuracy: 0.9406 - 20s/epoch - 47ms/step\n",
            "Epoch 141/1000\n",
            "\n",
            "Epoch 141: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2782 - accuracy: 0.9139 - val_loss: 0.2218 - val_accuracy: 0.9278 - 20s/epoch - 46ms/step\n",
            "Epoch 142/1000\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2789 - accuracy: 0.9128 - val_loss: 0.2478 - val_accuracy: 0.9234 - 20s/epoch - 46ms/step\n",
            "Epoch 143/1000\n",
            "\n",
            "Epoch 143: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2773 - accuracy: 0.9129 - val_loss: 0.1943 - val_accuracy: 0.9474 - 20s/epoch - 47ms/step\n",
            "Epoch 144/1000\n",
            "\n",
            "Epoch 144: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2821 - accuracy: 0.9120 - val_loss: 0.2583 - val_accuracy: 0.9194 - 19s/epoch - 44ms/step\n",
            "Epoch 145/1000\n",
            "\n",
            "Epoch 145: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2793 - accuracy: 0.9123 - val_loss: 0.2052 - val_accuracy: 0.9392 - 18s/epoch - 43ms/step\n",
            "Epoch 146/1000\n",
            "\n",
            "Epoch 146: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2754 - accuracy: 0.9144 - val_loss: 0.2213 - val_accuracy: 0.9386 - 19s/epoch - 43ms/step\n",
            "Epoch 147/1000\n",
            "\n",
            "Epoch 147: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2792 - accuracy: 0.9108 - val_loss: 0.1844 - val_accuracy: 0.9500 - 18s/epoch - 43ms/step\n",
            "Epoch 148/1000\n",
            "\n",
            "Epoch 148: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2745 - accuracy: 0.9155 - val_loss: 0.1932 - val_accuracy: 0.9422 - 19s/epoch - 44ms/step\n",
            "Epoch 149/1000\n",
            "\n",
            "Epoch 149: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2788 - accuracy: 0.9120 - val_loss: 0.2386 - val_accuracy: 0.9260 - 19s/epoch - 45ms/step\n",
            "Epoch 150/1000\n",
            "\n",
            "Epoch 150: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2766 - accuracy: 0.9134 - val_loss: 0.1913 - val_accuracy: 0.9444 - 19s/epoch - 44ms/step\n",
            "Epoch 151/1000\n",
            "\n",
            "Epoch 151: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2762 - accuracy: 0.9138 - val_loss: 0.2204 - val_accuracy: 0.9306 - 19s/epoch - 44ms/step\n",
            "Epoch 152/1000\n",
            "\n",
            "Epoch 152: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2766 - accuracy: 0.9127 - val_loss: 0.1875 - val_accuracy: 0.9462 - 19s/epoch - 45ms/step\n",
            "Epoch 153/1000\n",
            "\n",
            "Epoch 153: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2782 - accuracy: 0.9120 - val_loss: 0.2039 - val_accuracy: 0.9412 - 19s/epoch - 45ms/step\n",
            "Epoch 154/1000\n",
            "\n",
            "Epoch 154: val_accuracy did not improve from 0.95000\n",
            "429/429 - 21s - loss: 0.2791 - accuracy: 0.9125 - val_loss: 0.2318 - val_accuracy: 0.9272 - 21s/epoch - 50ms/step\n",
            "Epoch 155/1000\n",
            "\n",
            "Epoch 155: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2774 - accuracy: 0.9145 - val_loss: 0.2546 - val_accuracy: 0.9250 - 20s/epoch - 46ms/step\n",
            "Epoch 156/1000\n",
            "\n",
            "Epoch 156: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2789 - accuracy: 0.9137 - val_loss: 0.2378 - val_accuracy: 0.9304 - 19s/epoch - 43ms/step\n",
            "Epoch 157/1000\n",
            "\n",
            "Epoch 157: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2756 - accuracy: 0.9149 - val_loss: 0.1949 - val_accuracy: 0.9430 - 19s/epoch - 44ms/step\n",
            "Epoch 158/1000\n",
            "\n",
            "Epoch 158: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2731 - accuracy: 0.9153 - val_loss: 0.2130 - val_accuracy: 0.9360 - 18s/epoch - 43ms/step\n",
            "Epoch 159/1000\n",
            "\n",
            "Epoch 159: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2761 - accuracy: 0.9142 - val_loss: 0.2226 - val_accuracy: 0.9280 - 19s/epoch - 43ms/step\n",
            "Epoch 160/1000\n",
            "\n",
            "Epoch 160: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2736 - accuracy: 0.9134 - val_loss: 0.2186 - val_accuracy: 0.9326 - 18s/epoch - 43ms/step\n",
            "Epoch 161/1000\n",
            "\n",
            "Epoch 161: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2762 - accuracy: 0.9147 - val_loss: 0.1995 - val_accuracy: 0.9402 - 19s/epoch - 43ms/step\n",
            "Epoch 162/1000\n",
            "\n",
            "Epoch 162: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2785 - accuracy: 0.9125 - val_loss: 0.1940 - val_accuracy: 0.9462 - 19s/epoch - 45ms/step\n",
            "Epoch 163/1000\n",
            "\n",
            "Epoch 163: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2783 - accuracy: 0.9127 - val_loss: 0.2057 - val_accuracy: 0.9392 - 19s/epoch - 45ms/step\n",
            "Epoch 164/1000\n",
            "\n",
            "Epoch 164: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2741 - accuracy: 0.9147 - val_loss: 0.2119 - val_accuracy: 0.9382 - 20s/epoch - 46ms/step\n",
            "Epoch 165/1000\n",
            "\n",
            "Epoch 165: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2778 - accuracy: 0.9132 - val_loss: 0.2003 - val_accuracy: 0.9410 - 19s/epoch - 44ms/step\n",
            "Epoch 166/1000\n",
            "\n",
            "Epoch 166: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2755 - accuracy: 0.9147 - val_loss: 0.1895 - val_accuracy: 0.9458 - 20s/epoch - 46ms/step\n",
            "Epoch 167/1000\n",
            "\n",
            "Epoch 167: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2744 - accuracy: 0.9146 - val_loss: 0.2231 - val_accuracy: 0.9300 - 19s/epoch - 45ms/step\n",
            "Epoch 168/1000\n",
            "\n",
            "Epoch 168: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2757 - accuracy: 0.9130 - val_loss: 0.2119 - val_accuracy: 0.9384 - 19s/epoch - 44ms/step\n",
            "Epoch 169/1000\n",
            "\n",
            "Epoch 169: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2821 - accuracy: 0.9119 - val_loss: 0.2319 - val_accuracy: 0.9284 - 17s/epoch - 40ms/step\n",
            "Epoch 170/1000\n",
            "\n",
            "Epoch 170: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2757 - accuracy: 0.9139 - val_loss: 0.2554 - val_accuracy: 0.9286 - 17s/epoch - 39ms/step\n",
            "Epoch 171/1000\n",
            "\n",
            "Epoch 171: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2724 - accuracy: 0.9135 - val_loss: 0.2042 - val_accuracy: 0.9406 - 20s/epoch - 46ms/step\n",
            "Epoch 172/1000\n",
            "\n",
            "Epoch 172: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2756 - accuracy: 0.9148 - val_loss: 0.2383 - val_accuracy: 0.9256 - 19s/epoch - 44ms/step\n",
            "Epoch 173/1000\n",
            "\n",
            "Epoch 173: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2732 - accuracy: 0.9148 - val_loss: 0.1957 - val_accuracy: 0.9406 - 19s/epoch - 45ms/step\n",
            "Epoch 174/1000\n",
            "\n",
            "Epoch 174: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2747 - accuracy: 0.9135 - val_loss: 0.1937 - val_accuracy: 0.9442 - 20s/epoch - 46ms/step\n",
            "Epoch 175/1000\n",
            "\n",
            "Epoch 175: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2750 - accuracy: 0.9146 - val_loss: 0.2277 - val_accuracy: 0.9288 - 19s/epoch - 45ms/step\n",
            "Epoch 176/1000\n",
            "\n",
            "Epoch 176: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2733 - accuracy: 0.9149 - val_loss: 0.1959 - val_accuracy: 0.9434 - 20s/epoch - 46ms/step\n",
            "Epoch 177/1000\n",
            "\n",
            "Epoch 177: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2768 - accuracy: 0.9120 - val_loss: 0.2134 - val_accuracy: 0.9352 - 20s/epoch - 47ms/step\n",
            "Epoch 178/1000\n",
            "\n",
            "Epoch 178: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2754 - accuracy: 0.9140 - val_loss: 0.2301 - val_accuracy: 0.9348 - 20s/epoch - 47ms/step\n",
            "Epoch 179/1000\n",
            "\n",
            "Epoch 179: val_accuracy did not improve from 0.95000\n",
            "429/429 - 21s - loss: 0.2724 - accuracy: 0.9153 - val_loss: 0.1997 - val_accuracy: 0.9410 - 21s/epoch - 48ms/step\n",
            "Epoch 180/1000\n",
            "\n",
            "Epoch 180: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2743 - accuracy: 0.9133 - val_loss: 0.2239 - val_accuracy: 0.9274 - 20s/epoch - 47ms/step\n",
            "Epoch 181/1000\n",
            "\n",
            "Epoch 181: val_accuracy did not improve from 0.95000\n",
            "429/429 - 23s - loss: 0.2716 - accuracy: 0.9150 - val_loss: 0.2239 - val_accuracy: 0.9318 - 23s/epoch - 53ms/step\n",
            "Epoch 182/1000\n",
            "\n",
            "Epoch 182: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2736 - accuracy: 0.9144 - val_loss: 0.2095 - val_accuracy: 0.9434 - 19s/epoch - 44ms/step\n",
            "Epoch 183/1000\n",
            "\n",
            "Epoch 183: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2748 - accuracy: 0.9149 - val_loss: 0.2123 - val_accuracy: 0.9360 - 19s/epoch - 43ms/step\n",
            "Epoch 184/1000\n",
            "\n",
            "Epoch 184: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2748 - accuracy: 0.9147 - val_loss: 0.2021 - val_accuracy: 0.9398 - 18s/epoch - 43ms/step\n",
            "Epoch 185/1000\n",
            "\n",
            "Epoch 185: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2744 - accuracy: 0.9141 - val_loss: 0.2113 - val_accuracy: 0.9368 - 19s/epoch - 43ms/step\n",
            "Epoch 186/1000\n",
            "\n",
            "Epoch 186: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2729 - accuracy: 0.9131 - val_loss: 0.2269 - val_accuracy: 0.9292 - 18s/epoch - 42ms/step\n",
            "Epoch 187/1000\n",
            "\n",
            "Epoch 187: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2754 - accuracy: 0.9141 - val_loss: 0.2521 - val_accuracy: 0.9198 - 19s/epoch - 43ms/step\n",
            "Epoch 188/1000\n",
            "\n",
            "Epoch 188: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2710 - accuracy: 0.9139 - val_loss: 0.2404 - val_accuracy: 0.9292 - 18s/epoch - 42ms/step\n",
            "Epoch 189/1000\n",
            "\n",
            "Epoch 189: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2780 - accuracy: 0.9127 - val_loss: 0.1889 - val_accuracy: 0.9498 - 19s/epoch - 44ms/step\n",
            "Epoch 190/1000\n",
            "\n",
            "Epoch 190: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2723 - accuracy: 0.9151 - val_loss: 0.2308 - val_accuracy: 0.9320 - 19s/epoch - 45ms/step\n",
            "Epoch 191/1000\n",
            "\n",
            "Epoch 191: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2753 - accuracy: 0.9141 - val_loss: 0.2140 - val_accuracy: 0.9396 - 19s/epoch - 45ms/step\n",
            "Epoch 192/1000\n",
            "\n",
            "Epoch 192: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2737 - accuracy: 0.9164 - val_loss: 0.1863 - val_accuracy: 0.9462 - 19s/epoch - 44ms/step\n",
            "Epoch 193/1000\n",
            "\n",
            "Epoch 193: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2735 - accuracy: 0.9154 - val_loss: 0.2136 - val_accuracy: 0.9354 - 19s/epoch - 45ms/step\n",
            "Epoch 194/1000\n",
            "\n",
            "Epoch 194: val_accuracy did not improve from 0.95000\n",
            "429/429 - 21s - loss: 0.2726 - accuracy: 0.9154 - val_loss: 0.2079 - val_accuracy: 0.9378 - 21s/epoch - 48ms/step\n",
            "Epoch 195/1000\n",
            "\n",
            "Epoch 195: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2736 - accuracy: 0.9162 - val_loss: 0.2275 - val_accuracy: 0.9286 - 19s/epoch - 45ms/step\n",
            "Epoch 196/1000\n",
            "\n",
            "Epoch 196: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2738 - accuracy: 0.9136 - val_loss: 0.2023 - val_accuracy: 0.9434 - 19s/epoch - 45ms/step\n",
            "Epoch 197/1000\n",
            "\n",
            "Epoch 197: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2750 - accuracy: 0.9134 - val_loss: 0.2122 - val_accuracy: 0.9356 - 18s/epoch - 43ms/step\n",
            "Epoch 198/1000\n",
            "\n",
            "Epoch 198: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2712 - accuracy: 0.9154 - val_loss: 0.2160 - val_accuracy: 0.9360 - 18s/epoch - 42ms/step\n",
            "Epoch 199/1000\n",
            "\n",
            "Epoch 199: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2704 - accuracy: 0.9164 - val_loss: 0.2153 - val_accuracy: 0.9362 - 19s/epoch - 45ms/step\n",
            "Epoch 200/1000\n",
            "\n",
            "Epoch 200: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2736 - accuracy: 0.9140 - val_loss: 0.1980 - val_accuracy: 0.9408 - 18s/epoch - 42ms/step\n",
            "Epoch 201/1000\n",
            "\n",
            "Epoch 201: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2752 - accuracy: 0.9137 - val_loss: 0.2103 - val_accuracy: 0.9388 - 18s/epoch - 42ms/step\n",
            "Epoch 202/1000\n",
            "\n",
            "Epoch 202: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2755 - accuracy: 0.9152 - val_loss: 0.1868 - val_accuracy: 0.9476 - 18s/epoch - 42ms/step\n",
            "Epoch 203/1000\n",
            "\n",
            "Epoch 203: val_accuracy did not improve from 0.95000\n",
            "429/429 - 18s - loss: 0.2742 - accuracy: 0.9141 - val_loss: 0.2123 - val_accuracy: 0.9362 - 18s/epoch - 43ms/step\n",
            "Epoch 204/1000\n",
            "\n",
            "Epoch 204: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2692 - accuracy: 0.9162 - val_loss: 0.2087 - val_accuracy: 0.9418 - 19s/epoch - 43ms/step\n",
            "Epoch 205/1000\n",
            "\n",
            "Epoch 205: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2694 - accuracy: 0.9156 - val_loss: 0.2186 - val_accuracy: 0.9368 - 19s/epoch - 43ms/step\n",
            "Epoch 206/1000\n",
            "\n",
            "Epoch 206: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2708 - accuracy: 0.9160 - val_loss: 0.2180 - val_accuracy: 0.9338 - 19s/epoch - 43ms/step\n",
            "Epoch 207/1000\n",
            "\n",
            "Epoch 207: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2742 - accuracy: 0.9149 - val_loss: 0.2060 - val_accuracy: 0.9404 - 19s/epoch - 45ms/step\n",
            "Epoch 208/1000\n",
            "\n",
            "Epoch 208: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2680 - accuracy: 0.9161 - val_loss: 0.1831 - val_accuracy: 0.9498 - 19s/epoch - 45ms/step\n",
            "Epoch 209/1000\n",
            "\n",
            "Epoch 209: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2680 - accuracy: 0.9169 - val_loss: 0.2129 - val_accuracy: 0.9372 - 20s/epoch - 47ms/step\n",
            "Epoch 210/1000\n",
            "\n",
            "Epoch 210: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2704 - accuracy: 0.9151 - val_loss: 0.2266 - val_accuracy: 0.9304 - 19s/epoch - 44ms/step\n",
            "Epoch 211/1000\n",
            "\n",
            "Epoch 211: val_accuracy did not improve from 0.95000\n",
            "429/429 - 21s - loss: 0.2697 - accuracy: 0.9157 - val_loss: 0.2132 - val_accuracy: 0.9336 - 21s/epoch - 49ms/step\n",
            "Epoch 212/1000\n",
            "\n",
            "Epoch 212: val_accuracy did not improve from 0.95000\n",
            "429/429 - 20s - loss: 0.2689 - accuracy: 0.9177 - val_loss: 0.2239 - val_accuracy: 0.9332 - 20s/epoch - 47ms/step\n",
            "Epoch 213/1000\n",
            "\n",
            "Epoch 213: val_accuracy did not improve from 0.95000\n",
            "429/429 - 19s - loss: 0.2691 - accuracy: 0.9156 - val_loss: 0.2131 - val_accuracy: 0.9368 - 19s/epoch - 45ms/step\n",
            "Epoch 214/1000\n",
            "\n",
            "Epoch 214: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2735 - accuracy: 0.9147 - val_loss: 0.2259 - val_accuracy: 0.9312 - 17s/epoch - 39ms/step\n",
            "Epoch 215/1000\n",
            "\n",
            "Epoch 215: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2733 - accuracy: 0.9145 - val_loss: 0.1866 - val_accuracy: 0.9456 - 16s/epoch - 38ms/step\n",
            "Epoch 216/1000\n",
            "\n",
            "Epoch 216: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2696 - accuracy: 0.9162 - val_loss: 0.2173 - val_accuracy: 0.9356 - 16s/epoch - 38ms/step\n",
            "Epoch 217/1000\n",
            "\n",
            "Epoch 217: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2676 - accuracy: 0.9161 - val_loss: 0.1975 - val_accuracy: 0.9404 - 16s/epoch - 38ms/step\n",
            "Epoch 218/1000\n",
            "\n",
            "Epoch 218: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2684 - accuracy: 0.9160 - val_loss: 0.1932 - val_accuracy: 0.9404 - 16s/epoch - 38ms/step\n",
            "Epoch 219/1000\n",
            "\n",
            "Epoch 219: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2728 - accuracy: 0.9158 - val_loss: 0.2049 - val_accuracy: 0.9404 - 17s/epoch - 39ms/step\n",
            "Epoch 220/1000\n",
            "\n",
            "Epoch 220: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2711 - accuracy: 0.9161 - val_loss: 0.2017 - val_accuracy: 0.9406 - 17s/epoch - 39ms/step\n",
            "Epoch 221/1000\n",
            "\n",
            "Epoch 221: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2713 - accuracy: 0.9148 - val_loss: 0.2149 - val_accuracy: 0.9346 - 17s/epoch - 40ms/step\n",
            "Epoch 222/1000\n",
            "\n",
            "Epoch 222: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2721 - accuracy: 0.9148 - val_loss: 0.1992 - val_accuracy: 0.9464 - 17s/epoch - 40ms/step\n",
            "Epoch 223/1000\n",
            "\n",
            "Epoch 223: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2706 - accuracy: 0.9162 - val_loss: 0.2080 - val_accuracy: 0.9370 - 16s/epoch - 38ms/step\n",
            "Epoch 224/1000\n",
            "\n",
            "Epoch 224: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2671 - accuracy: 0.9157 - val_loss: 0.1917 - val_accuracy: 0.9470 - 17s/epoch - 39ms/step\n",
            "Epoch 225/1000\n",
            "\n",
            "Epoch 225: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2679 - accuracy: 0.9170 - val_loss: 0.2180 - val_accuracy: 0.9364 - 16s/epoch - 37ms/step\n",
            "Epoch 226/1000\n",
            "\n",
            "Epoch 226: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2709 - accuracy: 0.9158 - val_loss: 0.2099 - val_accuracy: 0.9378 - 16s/epoch - 38ms/step\n",
            "Epoch 227/1000\n",
            "\n",
            "Epoch 227: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2704 - accuracy: 0.9155 - val_loss: 0.1932 - val_accuracy: 0.9446 - 16s/epoch - 38ms/step\n",
            "Epoch 228/1000\n",
            "\n",
            "Epoch 228: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2690 - accuracy: 0.9156 - val_loss: 0.2068 - val_accuracy: 0.9412 - 16s/epoch - 37ms/step\n",
            "Epoch 229/1000\n",
            "\n",
            "Epoch 229: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2709 - accuracy: 0.9157 - val_loss: 0.2082 - val_accuracy: 0.9372 - 16s/epoch - 37ms/step\n",
            "Epoch 230/1000\n",
            "\n",
            "Epoch 230: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2714 - accuracy: 0.9165 - val_loss: 0.2113 - val_accuracy: 0.9380 - 16s/epoch - 37ms/step\n",
            "Epoch 231/1000\n",
            "\n",
            "Epoch 231: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2685 - accuracy: 0.9175 - val_loss: 0.2010 - val_accuracy: 0.9420 - 16s/epoch - 37ms/step\n",
            "Epoch 232/1000\n",
            "\n",
            "Epoch 232: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2720 - accuracy: 0.9150 - val_loss: 0.2428 - val_accuracy: 0.9318 - 16s/epoch - 37ms/step\n",
            "Epoch 233/1000\n",
            "\n",
            "Epoch 233: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2681 - accuracy: 0.9178 - val_loss: 0.2024 - val_accuracy: 0.9438 - 16s/epoch - 38ms/step\n",
            "Epoch 234/1000\n",
            "\n",
            "Epoch 234: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2704 - accuracy: 0.9156 - val_loss: 0.2035 - val_accuracy: 0.9382 - 16s/epoch - 38ms/step\n",
            "Epoch 235/1000\n",
            "\n",
            "Epoch 235: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2702 - accuracy: 0.9168 - val_loss: 0.2279 - val_accuracy: 0.9308 - 16s/epoch - 38ms/step\n",
            "Epoch 236/1000\n",
            "\n",
            "Epoch 236: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2674 - accuracy: 0.9170 - val_loss: 0.2246 - val_accuracy: 0.9340 - 17s/epoch - 41ms/step\n",
            "Epoch 237/1000\n",
            "\n",
            "Epoch 237: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2700 - accuracy: 0.9165 - val_loss: 0.2332 - val_accuracy: 0.9278 - 16s/epoch - 38ms/step\n",
            "Epoch 238/1000\n",
            "\n",
            "Epoch 238: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2706 - accuracy: 0.9169 - val_loss: 0.1941 - val_accuracy: 0.9430 - 16s/epoch - 37ms/step\n",
            "Epoch 239/1000\n",
            "\n",
            "Epoch 239: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2670 - accuracy: 0.9169 - val_loss: 0.1901 - val_accuracy: 0.9492 - 16s/epoch - 38ms/step\n",
            "Epoch 240/1000\n",
            "\n",
            "Epoch 240: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2676 - accuracy: 0.9172 - val_loss: 0.1957 - val_accuracy: 0.9424 - 16s/epoch - 37ms/step\n",
            "Epoch 241/1000\n",
            "\n",
            "Epoch 241: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2732 - accuracy: 0.9156 - val_loss: 0.1799 - val_accuracy: 0.9492 - 16s/epoch - 37ms/step\n",
            "Epoch 242/1000\n",
            "\n",
            "Epoch 242: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2671 - accuracy: 0.9191 - val_loss: 0.1844 - val_accuracy: 0.9446 - 16s/epoch - 37ms/step\n",
            "Epoch 243/1000\n",
            "\n",
            "Epoch 243: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2703 - accuracy: 0.9159 - val_loss: 0.2320 - val_accuracy: 0.9356 - 16s/epoch - 37ms/step\n",
            "Epoch 244/1000\n",
            "\n",
            "Epoch 244: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2680 - accuracy: 0.9178 - val_loss: 0.2051 - val_accuracy: 0.9404 - 16s/epoch - 37ms/step\n",
            "Epoch 245/1000\n",
            "\n",
            "Epoch 245: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2645 - accuracy: 0.9182 - val_loss: 0.1869 - val_accuracy: 0.9494 - 16s/epoch - 37ms/step\n",
            "Epoch 246/1000\n",
            "\n",
            "Epoch 246: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2709 - accuracy: 0.9165 - val_loss: 0.2049 - val_accuracy: 0.9396 - 16s/epoch - 38ms/step\n",
            "Epoch 247/1000\n",
            "\n",
            "Epoch 247: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2726 - accuracy: 0.9152 - val_loss: 0.2142 - val_accuracy: 0.9346 - 16s/epoch - 38ms/step\n",
            "Epoch 248/1000\n",
            "\n",
            "Epoch 248: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2689 - accuracy: 0.9156 - val_loss: 0.2228 - val_accuracy: 0.9312 - 16s/epoch - 38ms/step\n",
            "Epoch 249/1000\n",
            "\n",
            "Epoch 249: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2666 - accuracy: 0.9172 - val_loss: 0.2054 - val_accuracy: 0.9418 - 17s/epoch - 39ms/step\n",
            "Epoch 250/1000\n",
            "\n",
            "Epoch 250: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2732 - accuracy: 0.9151 - val_loss: 0.2332 - val_accuracy: 0.9258 - 16s/epoch - 38ms/step\n",
            "Epoch 251/1000\n",
            "\n",
            "Epoch 251: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2686 - accuracy: 0.9165 - val_loss: 0.1955 - val_accuracy: 0.9402 - 17s/epoch - 39ms/step\n",
            "Epoch 252/1000\n",
            "\n",
            "Epoch 252: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2640 - accuracy: 0.9181 - val_loss: 0.1931 - val_accuracy: 0.9424 - 16s/epoch - 38ms/step\n",
            "Epoch 253/1000\n",
            "\n",
            "Epoch 253: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2698 - accuracy: 0.9164 - val_loss: 0.1924 - val_accuracy: 0.9428 - 16s/epoch - 37ms/step\n",
            "Epoch 254/1000\n",
            "\n",
            "Epoch 254: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2664 - accuracy: 0.9180 - val_loss: 0.1837 - val_accuracy: 0.9464 - 16s/epoch - 38ms/step\n",
            "Epoch 255/1000\n",
            "\n",
            "Epoch 255: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2693 - accuracy: 0.9168 - val_loss: 0.1913 - val_accuracy: 0.9450 - 16s/epoch - 37ms/step\n",
            "Epoch 256/1000\n",
            "\n",
            "Epoch 256: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2689 - accuracy: 0.9180 - val_loss: 0.1977 - val_accuracy: 0.9408 - 16s/epoch - 37ms/step\n",
            "Epoch 257/1000\n",
            "\n",
            "Epoch 257: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2694 - accuracy: 0.9164 - val_loss: 0.2112 - val_accuracy: 0.9398 - 16s/epoch - 37ms/step\n",
            "Epoch 258/1000\n",
            "\n",
            "Epoch 258: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2696 - accuracy: 0.9165 - val_loss: 0.2066 - val_accuracy: 0.9422 - 16s/epoch - 37ms/step\n",
            "Epoch 259/1000\n",
            "\n",
            "Epoch 259: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2653 - accuracy: 0.9166 - val_loss: 0.2017 - val_accuracy: 0.9398 - 16s/epoch - 37ms/step\n",
            "Epoch 260/1000\n",
            "\n",
            "Epoch 260: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2662 - accuracy: 0.9164 - val_loss: 0.2007 - val_accuracy: 0.9418 - 16s/epoch - 37ms/step\n",
            "Epoch 261/1000\n",
            "\n",
            "Epoch 261: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2712 - accuracy: 0.9159 - val_loss: 0.2083 - val_accuracy: 0.9386 - 16s/epoch - 38ms/step\n",
            "Epoch 262/1000\n",
            "\n",
            "Epoch 262: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2674 - accuracy: 0.9162 - val_loss: 0.2028 - val_accuracy: 0.9418 - 16s/epoch - 38ms/step\n",
            "Epoch 263/1000\n",
            "\n",
            "Epoch 263: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2676 - accuracy: 0.9168 - val_loss: 0.2070 - val_accuracy: 0.9374 - 16s/epoch - 38ms/step\n",
            "Epoch 264/1000\n",
            "\n",
            "Epoch 264: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2715 - accuracy: 0.9154 - val_loss: 0.1977 - val_accuracy: 0.9400 - 17s/epoch - 40ms/step\n",
            "Epoch 265/1000\n",
            "\n",
            "Epoch 265: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2696 - accuracy: 0.9164 - val_loss: 0.1999 - val_accuracy: 0.9444 - 17s/epoch - 39ms/step\n",
            "Epoch 266/1000\n",
            "\n",
            "Epoch 266: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2690 - accuracy: 0.9163 - val_loss: 0.2174 - val_accuracy: 0.9370 - 17s/epoch - 39ms/step\n",
            "Epoch 267/1000\n",
            "\n",
            "Epoch 267: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2703 - accuracy: 0.9167 - val_loss: 0.2007 - val_accuracy: 0.9426 - 16s/epoch - 37ms/step\n",
            "Epoch 268/1000\n",
            "\n",
            "Epoch 268: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2697 - accuracy: 0.9161 - val_loss: 0.2150 - val_accuracy: 0.9374 - 16s/epoch - 38ms/step\n",
            "Epoch 269/1000\n",
            "\n",
            "Epoch 269: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2704 - accuracy: 0.9159 - val_loss: 0.2193 - val_accuracy: 0.9364 - 17s/epoch - 39ms/step\n",
            "Epoch 270/1000\n",
            "\n",
            "Epoch 270: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2673 - accuracy: 0.9181 - val_loss: 0.2108 - val_accuracy: 0.9390 - 16s/epoch - 37ms/step\n",
            "Epoch 271/1000\n",
            "\n",
            "Epoch 271: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2710 - accuracy: 0.9158 - val_loss: 0.1902 - val_accuracy: 0.9470 - 16s/epoch - 37ms/step\n",
            "Epoch 272/1000\n",
            "\n",
            "Epoch 272: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2653 - accuracy: 0.9169 - val_loss: 0.2260 - val_accuracy: 0.9334 - 16s/epoch - 37ms/step\n",
            "Epoch 273/1000\n",
            "\n",
            "Epoch 273: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2667 - accuracy: 0.9162 - val_loss: 0.1852 - val_accuracy: 0.9494 - 16s/epoch - 38ms/step\n",
            "Epoch 274/1000\n",
            "\n",
            "Epoch 274: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2681 - accuracy: 0.9161 - val_loss: 0.2095 - val_accuracy: 0.9392 - 16s/epoch - 38ms/step\n",
            "Epoch 275/1000\n",
            "\n",
            "Epoch 275: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2673 - accuracy: 0.9175 - val_loss: 0.2453 - val_accuracy: 0.9248 - 17s/epoch - 39ms/step\n",
            "Epoch 276/1000\n",
            "\n",
            "Epoch 276: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2712 - accuracy: 0.9162 - val_loss: 0.2073 - val_accuracy: 0.9384 - 16s/epoch - 38ms/step\n",
            "Epoch 277/1000\n",
            "\n",
            "Epoch 277: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2666 - accuracy: 0.9172 - val_loss: 0.2320 - val_accuracy: 0.9306 - 17s/epoch - 39ms/step\n",
            "Epoch 278/1000\n",
            "\n",
            "Epoch 278: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2693 - accuracy: 0.9148 - val_loss: 0.1994 - val_accuracy: 0.9418 - 16s/epoch - 38ms/step\n",
            "Epoch 279/1000\n",
            "\n",
            "Epoch 279: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2637 - accuracy: 0.9181 - val_loss: 0.2268 - val_accuracy: 0.9294 - 17s/epoch - 39ms/step\n",
            "Epoch 280/1000\n",
            "\n",
            "Epoch 280: val_accuracy did not improve from 0.95000\n",
            "429/429 - 17s - loss: 0.2624 - accuracy: 0.9188 - val_loss: 0.2152 - val_accuracy: 0.9394 - 17s/epoch - 39ms/step\n",
            "Epoch 281/1000\n",
            "\n",
            "Epoch 281: val_accuracy did not improve from 0.95000\n",
            "429/429 - 16s - loss: 0.2690 - accuracy: 0.9162 - val_loss: 0.2442 - val_accuracy: 0.9306 - 16s/epoch - 37ms/step\n",
            "Epoch 282/1000\n",
            "\n",
            "Epoch 282: val_accuracy improved from 0.95000 to 0.95320, saving model to best_model,keras\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model,keras\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "429/429 - 18s - loss: 0.2681 - accuracy: 0.9169 - val_loss: 0.1855 - val_accuracy: 0.9532 - 18s/epoch - 42ms/step\n",
            "Epoch 283/1000\n",
            "\n",
            "Epoch 283: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2644 - accuracy: 0.9175 - val_loss: 0.2083 - val_accuracy: 0.9424 - 16s/epoch - 38ms/step\n",
            "Epoch 284/1000\n",
            "\n",
            "Epoch 284: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2699 - accuracy: 0.9155 - val_loss: 0.1930 - val_accuracy: 0.9482 - 16s/epoch - 37ms/step\n",
            "Epoch 285/1000\n",
            "\n",
            "Epoch 285: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2697 - accuracy: 0.9159 - val_loss: 0.2032 - val_accuracy: 0.9448 - 16s/epoch - 37ms/step\n",
            "Epoch 286/1000\n",
            "\n",
            "Epoch 286: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2680 - accuracy: 0.9176 - val_loss: 0.2483 - val_accuracy: 0.9228 - 16s/epoch - 38ms/step\n",
            "Epoch 287/1000\n",
            "\n",
            "Epoch 287: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2710 - accuracy: 0.9159 - val_loss: 0.1856 - val_accuracy: 0.9490 - 17s/epoch - 39ms/step\n",
            "Epoch 288/1000\n",
            "\n",
            "Epoch 288: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2682 - accuracy: 0.9167 - val_loss: 0.1868 - val_accuracy: 0.9476 - 16s/epoch - 37ms/step\n",
            "Epoch 289/1000\n",
            "\n",
            "Epoch 289: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2667 - accuracy: 0.9179 - val_loss: 0.2173 - val_accuracy: 0.9418 - 16s/epoch - 38ms/step\n",
            "Epoch 290/1000\n",
            "\n",
            "Epoch 290: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2663 - accuracy: 0.9174 - val_loss: 0.2264 - val_accuracy: 0.9278 - 16s/epoch - 38ms/step\n",
            "Epoch 291/1000\n",
            "\n",
            "Epoch 291: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2658 - accuracy: 0.9175 - val_loss: 0.2089 - val_accuracy: 0.9412 - 17s/epoch - 39ms/step\n",
            "Epoch 292/1000\n",
            "\n",
            "Epoch 292: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2683 - accuracy: 0.9167 - val_loss: 0.1954 - val_accuracy: 0.9448 - 17s/epoch - 39ms/step\n",
            "Epoch 293/1000\n",
            "\n",
            "Epoch 293: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2645 - accuracy: 0.9181 - val_loss: 0.1968 - val_accuracy: 0.9450 - 19s/epoch - 44ms/step\n",
            "Epoch 294/1000\n",
            "\n",
            "Epoch 294: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2666 - accuracy: 0.9165 - val_loss: 0.2780 - val_accuracy: 0.9166 - 19s/epoch - 45ms/step\n",
            "Epoch 295/1000\n",
            "\n",
            "Epoch 295: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2688 - accuracy: 0.9159 - val_loss: 0.1946 - val_accuracy: 0.9446 - 18s/epoch - 41ms/step\n",
            "Epoch 296/1000\n",
            "\n",
            "Epoch 296: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2695 - accuracy: 0.9162 - val_loss: 0.2014 - val_accuracy: 0.9456 - 18s/epoch - 42ms/step\n",
            "Epoch 297/1000\n",
            "\n",
            "Epoch 297: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2684 - accuracy: 0.9176 - val_loss: 0.1924 - val_accuracy: 0.9440 - 17s/epoch - 41ms/step\n",
            "Epoch 298/1000\n",
            "\n",
            "Epoch 298: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2701 - accuracy: 0.9159 - val_loss: 0.1986 - val_accuracy: 0.9466 - 17s/epoch - 40ms/step\n",
            "Epoch 299/1000\n",
            "\n",
            "Epoch 299: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2695 - accuracy: 0.9158 - val_loss: 0.2450 - val_accuracy: 0.9260 - 18s/epoch - 41ms/step\n",
            "Epoch 300/1000\n",
            "\n",
            "Epoch 300: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2634 - accuracy: 0.9183 - val_loss: 0.2028 - val_accuracy: 0.9372 - 17s/epoch - 41ms/step\n",
            "Epoch 301/1000\n",
            "\n",
            "Epoch 301: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2665 - accuracy: 0.9178 - val_loss: 0.2057 - val_accuracy: 0.9428 - 18s/epoch - 42ms/step\n",
            "Epoch 302/1000\n",
            "\n",
            "Epoch 302: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2648 - accuracy: 0.9177 - val_loss: 0.2061 - val_accuracy: 0.9426 - 18s/epoch - 41ms/step\n",
            "Epoch 303/1000\n",
            "\n",
            "Epoch 303: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2710 - accuracy: 0.9155 - val_loss: 0.2076 - val_accuracy: 0.9406 - 18s/epoch - 43ms/step\n",
            "Epoch 304/1000\n",
            "\n",
            "Epoch 304: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2661 - accuracy: 0.9166 - val_loss: 0.1959 - val_accuracy: 0.9426 - 18s/epoch - 41ms/step\n",
            "Epoch 305/1000\n",
            "\n",
            "Epoch 305: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2647 - accuracy: 0.9183 - val_loss: 0.2100 - val_accuracy: 0.9328 - 19s/epoch - 44ms/step\n",
            "Epoch 306/1000\n",
            "\n",
            "Epoch 306: val_accuracy did not improve from 0.95320\n",
            "429/429 - 20s - loss: 0.2657 - accuracy: 0.9177 - val_loss: 0.1980 - val_accuracy: 0.9424 - 20s/epoch - 47ms/step\n",
            "Epoch 307/1000\n",
            "\n",
            "Epoch 307: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2642 - accuracy: 0.9186 - val_loss: 0.2040 - val_accuracy: 0.9390 - 18s/epoch - 43ms/step\n",
            "Epoch 308/1000\n",
            "\n",
            "Epoch 308: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2677 - accuracy: 0.9166 - val_loss: 0.1956 - val_accuracy: 0.9460 - 19s/epoch - 43ms/step\n",
            "Epoch 309/1000\n",
            "\n",
            "Epoch 309: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2686 - accuracy: 0.9172 - val_loss: 0.2109 - val_accuracy: 0.9392 - 18s/epoch - 42ms/step\n",
            "Epoch 310/1000\n",
            "\n",
            "Epoch 310: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2615 - accuracy: 0.9192 - val_loss: 0.1992 - val_accuracy: 0.9442 - 17s/epoch - 40ms/step\n",
            "Epoch 311/1000\n",
            "\n",
            "Epoch 311: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2646 - accuracy: 0.9179 - val_loss: 0.1923 - val_accuracy: 0.9442 - 18s/epoch - 42ms/step\n",
            "Epoch 312/1000\n",
            "\n",
            "Epoch 312: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2640 - accuracy: 0.9188 - val_loss: 0.2225 - val_accuracy: 0.9352 - 17s/epoch - 40ms/step\n",
            "Epoch 313/1000\n",
            "\n",
            "Epoch 313: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2691 - accuracy: 0.9158 - val_loss: 0.2149 - val_accuracy: 0.9382 - 17s/epoch - 41ms/step\n",
            "Epoch 314/1000\n",
            "\n",
            "Epoch 314: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2664 - accuracy: 0.9173 - val_loss: 0.2097 - val_accuracy: 0.9374 - 18s/epoch - 41ms/step\n",
            "Epoch 315/1000\n",
            "\n",
            "Epoch 315: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2685 - accuracy: 0.9172 - val_loss: 0.2227 - val_accuracy: 0.9312 - 18s/epoch - 42ms/step\n",
            "Epoch 316/1000\n",
            "\n",
            "Epoch 316: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2662 - accuracy: 0.9178 - val_loss: 0.2000 - val_accuracy: 0.9382 - 18s/epoch - 43ms/step\n",
            "Epoch 317/1000\n",
            "\n",
            "Epoch 317: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2634 - accuracy: 0.9180 - val_loss: 0.2198 - val_accuracy: 0.9344 - 18s/epoch - 43ms/step\n",
            "Epoch 318/1000\n",
            "\n",
            "Epoch 318: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2659 - accuracy: 0.9177 - val_loss: 0.2104 - val_accuracy: 0.9362 - 18s/epoch - 42ms/step\n",
            "Epoch 319/1000\n",
            "\n",
            "Epoch 319: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2649 - accuracy: 0.9176 - val_loss: 0.2341 - val_accuracy: 0.9298 - 18s/epoch - 43ms/step\n",
            "Epoch 320/1000\n",
            "\n",
            "Epoch 320: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2669 - accuracy: 0.9163 - val_loss: 0.2176 - val_accuracy: 0.9348 - 19s/epoch - 44ms/step\n",
            "Epoch 321/1000\n",
            "\n",
            "Epoch 321: val_accuracy did not improve from 0.95320\n",
            "429/429 - 20s - loss: 0.2663 - accuracy: 0.9181 - val_loss: 0.1847 - val_accuracy: 0.9464 - 20s/epoch - 47ms/step\n",
            "Epoch 322/1000\n",
            "\n",
            "Epoch 322: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2676 - accuracy: 0.9172 - val_loss: 0.1968 - val_accuracy: 0.9446 - 19s/epoch - 43ms/step\n",
            "Epoch 323/1000\n",
            "\n",
            "Epoch 323: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2681 - accuracy: 0.9182 - val_loss: 0.2038 - val_accuracy: 0.9380 - 17s/epoch - 41ms/step\n",
            "Epoch 324/1000\n",
            "\n",
            "Epoch 324: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2675 - accuracy: 0.9164 - val_loss: 0.1977 - val_accuracy: 0.9450 - 16s/epoch - 38ms/step\n",
            "Epoch 325/1000\n",
            "\n",
            "Epoch 325: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2631 - accuracy: 0.9168 - val_loss: 0.1965 - val_accuracy: 0.9378 - 16s/epoch - 38ms/step\n",
            "Epoch 326/1000\n",
            "\n",
            "Epoch 326: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2611 - accuracy: 0.9185 - val_loss: 0.2200 - val_accuracy: 0.9368 - 16s/epoch - 38ms/step\n",
            "Epoch 327/1000\n",
            "\n",
            "Epoch 327: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2649 - accuracy: 0.9168 - val_loss: 0.1840 - val_accuracy: 0.9468 - 16s/epoch - 38ms/step\n",
            "Epoch 328/1000\n",
            "\n",
            "Epoch 328: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2624 - accuracy: 0.9184 - val_loss: 0.2019 - val_accuracy: 0.9428 - 16s/epoch - 38ms/step\n",
            "Epoch 329/1000\n",
            "\n",
            "Epoch 329: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2676 - accuracy: 0.9162 - val_loss: 0.1959 - val_accuracy: 0.9426 - 17s/epoch - 39ms/step\n",
            "Epoch 330/1000\n",
            "\n",
            "Epoch 330: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2612 - accuracy: 0.9189 - val_loss: 0.2092 - val_accuracy: 0.9362 - 17s/epoch - 39ms/step\n",
            "Epoch 331/1000\n",
            "\n",
            "Epoch 331: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2646 - accuracy: 0.9175 - val_loss: 0.1921 - val_accuracy: 0.9460 - 17s/epoch - 39ms/step\n",
            "Epoch 332/1000\n",
            "\n",
            "Epoch 332: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2678 - accuracy: 0.9152 - val_loss: 0.2067 - val_accuracy: 0.9404 - 17s/epoch - 39ms/step\n",
            "Epoch 333/1000\n",
            "\n",
            "Epoch 333: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2662 - accuracy: 0.9176 - val_loss: 0.1886 - val_accuracy: 0.9456 - 17s/epoch - 40ms/step\n",
            "Epoch 334/1000\n",
            "\n",
            "Epoch 334: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2654 - accuracy: 0.9172 - val_loss: 0.2022 - val_accuracy: 0.9446 - 18s/epoch - 42ms/step\n",
            "Epoch 335/1000\n",
            "\n",
            "Epoch 335: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2660 - accuracy: 0.9188 - val_loss: 0.1989 - val_accuracy: 0.9418 - 18s/epoch - 41ms/step\n",
            "Epoch 336/1000\n",
            "\n",
            "Epoch 336: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2643 - accuracy: 0.9190 - val_loss: 0.2027 - val_accuracy: 0.9416 - 17s/epoch - 40ms/step\n",
            "Epoch 337/1000\n",
            "\n",
            "Epoch 337: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2660 - accuracy: 0.9172 - val_loss: 0.1915 - val_accuracy: 0.9442 - 16s/epoch - 38ms/step\n",
            "Epoch 338/1000\n",
            "\n",
            "Epoch 338: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2671 - accuracy: 0.9172 - val_loss: 0.1977 - val_accuracy: 0.9418 - 16s/epoch - 38ms/step\n",
            "Epoch 339/1000\n",
            "\n",
            "Epoch 339: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2624 - accuracy: 0.9178 - val_loss: 0.2148 - val_accuracy: 0.9358 - 16s/epoch - 38ms/step\n",
            "Epoch 340/1000\n",
            "\n",
            "Epoch 340: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2677 - accuracy: 0.9178 - val_loss: 0.1948 - val_accuracy: 0.9442 - 16s/epoch - 38ms/step\n",
            "Epoch 341/1000\n",
            "\n",
            "Epoch 341: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2675 - accuracy: 0.9183 - val_loss: 0.1913 - val_accuracy: 0.9472 - 18s/epoch - 42ms/step\n",
            "Epoch 342/1000\n",
            "\n",
            "Epoch 342: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2638 - accuracy: 0.9190 - val_loss: 0.2113 - val_accuracy: 0.9408 - 18s/epoch - 42ms/step\n",
            "Epoch 343/1000\n",
            "\n",
            "Epoch 343: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2639 - accuracy: 0.9186 - val_loss: 0.1891 - val_accuracy: 0.9498 - 19s/epoch - 43ms/step\n",
            "Epoch 344/1000\n",
            "\n",
            "Epoch 344: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2640 - accuracy: 0.9184 - val_loss: 0.2022 - val_accuracy: 0.9400 - 19s/epoch - 43ms/step\n",
            "Epoch 345/1000\n",
            "\n",
            "Epoch 345: val_accuracy did not improve from 0.95320\n",
            "429/429 - 20s - loss: 0.2633 - accuracy: 0.9182 - val_loss: 0.1982 - val_accuracy: 0.9428 - 20s/epoch - 46ms/step\n",
            "Epoch 346/1000\n",
            "\n",
            "Epoch 346: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2673 - accuracy: 0.9170 - val_loss: 0.1937 - val_accuracy: 0.9444 - 19s/epoch - 45ms/step\n",
            "Epoch 347/1000\n",
            "\n",
            "Epoch 347: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2664 - accuracy: 0.9179 - val_loss: 0.1952 - val_accuracy: 0.9402 - 19s/epoch - 45ms/step\n",
            "Epoch 348/1000\n",
            "\n",
            "Epoch 348: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2644 - accuracy: 0.9179 - val_loss: 0.1829 - val_accuracy: 0.9484 - 19s/epoch - 44ms/step\n",
            "Epoch 349/1000\n",
            "\n",
            "Epoch 349: val_accuracy did not improve from 0.95320\n",
            "429/429 - 21s - loss: 0.2631 - accuracy: 0.9198 - val_loss: 0.1801 - val_accuracy: 0.9520 - 21s/epoch - 49ms/step\n",
            "Epoch 350/1000\n",
            "\n",
            "Epoch 350: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2658 - accuracy: 0.9186 - val_loss: 0.2020 - val_accuracy: 0.9414 - 19s/epoch - 44ms/step\n",
            "Epoch 351/1000\n",
            "\n",
            "Epoch 351: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2625 - accuracy: 0.9180 - val_loss: 0.2039 - val_accuracy: 0.9394 - 19s/epoch - 44ms/step\n",
            "Epoch 352/1000\n",
            "\n",
            "Epoch 352: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2629 - accuracy: 0.9173 - val_loss: 0.1796 - val_accuracy: 0.9504 - 18s/epoch - 43ms/step\n",
            "Epoch 353/1000\n",
            "\n",
            "Epoch 353: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2658 - accuracy: 0.9182 - val_loss: 0.2133 - val_accuracy: 0.9408 - 18s/epoch - 42ms/step\n",
            "Epoch 354/1000\n",
            "\n",
            "Epoch 354: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2663 - accuracy: 0.9172 - val_loss: 0.1957 - val_accuracy: 0.9454 - 19s/epoch - 44ms/step\n",
            "Epoch 355/1000\n",
            "\n",
            "Epoch 355: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2656 - accuracy: 0.9174 - val_loss: 0.2065 - val_accuracy: 0.9400 - 18s/epoch - 43ms/step\n",
            "Epoch 356/1000\n",
            "\n",
            "Epoch 356: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2667 - accuracy: 0.9194 - val_loss: 0.1849 - val_accuracy: 0.9480 - 19s/epoch - 43ms/step\n",
            "Epoch 357/1000\n",
            "\n",
            "Epoch 357: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2664 - accuracy: 0.9168 - val_loss: 0.2061 - val_accuracy: 0.9380 - 19s/epoch - 43ms/step\n",
            "Epoch 358/1000\n",
            "\n",
            "Epoch 358: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2654 - accuracy: 0.9177 - val_loss: 0.2072 - val_accuracy: 0.9398 - 19s/epoch - 45ms/step\n",
            "Epoch 359/1000\n",
            "\n",
            "Epoch 359: val_accuracy did not improve from 0.95320\n",
            "429/429 - 20s - loss: 0.2642 - accuracy: 0.9178 - val_loss: 0.2112 - val_accuracy: 0.9352 - 20s/epoch - 46ms/step\n",
            "Epoch 360/1000\n",
            "\n",
            "Epoch 360: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2622 - accuracy: 0.9177 - val_loss: 0.2158 - val_accuracy: 0.9388 - 19s/epoch - 44ms/step\n",
            "Epoch 361/1000\n",
            "\n",
            "Epoch 361: val_accuracy did not improve from 0.95320\n",
            "429/429 - 20s - loss: 0.2630 - accuracy: 0.9192 - val_loss: 0.1927 - val_accuracy: 0.9446 - 20s/epoch - 47ms/step\n",
            "Epoch 362/1000\n",
            "\n",
            "Epoch 362: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2620 - accuracy: 0.9181 - val_loss: 0.1893 - val_accuracy: 0.9458 - 19s/epoch - 45ms/step\n",
            "Epoch 363/1000\n",
            "\n",
            "Epoch 363: val_accuracy did not improve from 0.95320\n",
            "429/429 - 22s - loss: 0.2631 - accuracy: 0.9196 - val_loss: 0.1887 - val_accuracy: 0.9478 - 22s/epoch - 52ms/step\n",
            "Epoch 364/1000\n",
            "\n",
            "Epoch 364: val_accuracy did not improve from 0.95320\n",
            "429/429 - 21s - loss: 0.2621 - accuracy: 0.9192 - val_loss: 0.1867 - val_accuracy: 0.9478 - 21s/epoch - 50ms/step\n",
            "Epoch 365/1000\n",
            "\n",
            "Epoch 365: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2617 - accuracy: 0.9190 - val_loss: 0.2110 - val_accuracy: 0.9388 - 18s/epoch - 42ms/step\n",
            "Epoch 366/1000\n",
            "\n",
            "Epoch 366: val_accuracy did not improve from 0.95320\n",
            "429/429 - 20s - loss: 0.2665 - accuracy: 0.9173 - val_loss: 0.1853 - val_accuracy: 0.9488 - 20s/epoch - 46ms/step\n",
            "Epoch 367/1000\n",
            "\n",
            "Epoch 367: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2636 - accuracy: 0.9177 - val_loss: 0.2086 - val_accuracy: 0.9384 - 18s/epoch - 41ms/step\n",
            "Epoch 368/1000\n",
            "\n",
            "Epoch 368: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2651 - accuracy: 0.9174 - val_loss: 0.2069 - val_accuracy: 0.9402 - 18s/epoch - 42ms/step\n",
            "Epoch 369/1000\n",
            "\n",
            "Epoch 369: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2656 - accuracy: 0.9184 - val_loss: 0.2247 - val_accuracy: 0.9282 - 18s/epoch - 43ms/step\n",
            "Epoch 370/1000\n",
            "\n",
            "Epoch 370: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2600 - accuracy: 0.9194 - val_loss: 0.2349 - val_accuracy: 0.9300 - 18s/epoch - 41ms/step\n",
            "Epoch 371/1000\n",
            "\n",
            "Epoch 371: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2657 - accuracy: 0.9184 - val_loss: 0.1853 - val_accuracy: 0.9458 - 18s/epoch - 43ms/step\n",
            "Epoch 372/1000\n",
            "\n",
            "Epoch 372: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2640 - accuracy: 0.9162 - val_loss: 0.1778 - val_accuracy: 0.9512 - 18s/epoch - 42ms/step\n",
            "Epoch 373/1000\n",
            "\n",
            "Epoch 373: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2697 - accuracy: 0.9165 - val_loss: 0.1979 - val_accuracy: 0.9438 - 18s/epoch - 42ms/step\n",
            "Epoch 374/1000\n",
            "\n",
            "Epoch 374: val_accuracy did not improve from 0.95320\n",
            "429/429 - 19s - loss: 0.2655 - accuracy: 0.9178 - val_loss: 0.1999 - val_accuracy: 0.9390 - 19s/epoch - 44ms/step\n",
            "Epoch 375/1000\n",
            "\n",
            "Epoch 375: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2632 - accuracy: 0.9191 - val_loss: 0.2102 - val_accuracy: 0.9328 - 18s/epoch - 42ms/step\n",
            "Epoch 376/1000\n",
            "\n",
            "Epoch 376: val_accuracy did not improve from 0.95320\n",
            "429/429 - 20s - loss: 0.2647 - accuracy: 0.9170 - val_loss: 0.1986 - val_accuracy: 0.9434 - 20s/epoch - 45ms/step\n",
            "Epoch 377/1000\n",
            "\n",
            "Epoch 377: val_accuracy did not improve from 0.95320\n",
            "429/429 - 42s - loss: 0.2653 - accuracy: 0.9179 - val_loss: 0.1865 - val_accuracy: 0.9478 - 42s/epoch - 98ms/step\n",
            "Epoch 378/1000\n",
            "\n",
            "Epoch 378: val_accuracy did not improve from 0.95320\n",
            "429/429 - 20s - loss: 0.2641 - accuracy: 0.9174 - val_loss: 0.1935 - val_accuracy: 0.9438 - 20s/epoch - 47ms/step\n",
            "Epoch 379/1000\n",
            "\n",
            "Epoch 379: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2608 - accuracy: 0.9181 - val_loss: 0.1929 - val_accuracy: 0.9458 - 17s/epoch - 40ms/step\n",
            "Epoch 380/1000\n",
            "\n",
            "Epoch 380: val_accuracy did not improve from 0.95320\n",
            "429/429 - 18s - loss: 0.2665 - accuracy: 0.9185 - val_loss: 0.1895 - val_accuracy: 0.9456 - 18s/epoch - 41ms/step\n",
            "Epoch 381/1000\n",
            "\n",
            "Epoch 381: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2644 - accuracy: 0.9171 - val_loss: 0.1811 - val_accuracy: 0.9484 - 17s/epoch - 40ms/step\n",
            "Epoch 382/1000\n",
            "\n",
            "Epoch 382: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2608 - accuracy: 0.9193 - val_loss: 0.2024 - val_accuracy: 0.9420 - 17s/epoch - 39ms/step\n",
            "Epoch 383/1000\n",
            "\n",
            "Epoch 383: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2598 - accuracy: 0.9190 - val_loss: 0.2269 - val_accuracy: 0.9282 - 17s/epoch - 39ms/step\n",
            "Epoch 384/1000\n",
            "\n",
            "Epoch 384: val_accuracy did not improve from 0.95320\n",
            "429/429 - 16s - loss: 0.2658 - accuracy: 0.9179 - val_loss: 0.2211 - val_accuracy: 0.9356 - 16s/epoch - 38ms/step\n",
            "Epoch 385/1000\n",
            "\n",
            "Epoch 385: val_accuracy did not improve from 0.95320\n",
            "429/429 - 17s - loss: 0.2636 - accuracy: 0.9182 - val_loss: 0.1889 - val_accuracy: 0.9456 - 17s/epoch - 40ms/step\n",
            "Epoch 386/1000\n",
            "\n",
            "Epoch 386: val_accuracy did not improve from 0.95320\n",
            "429/429 - 21s - loss: 0.2635 - accuracy: 0.9189 - val_loss: 0.1996 - val_accuracy: 0.9412 - 21s/epoch - 50ms/step\n",
            "Epoch 387/1000\n"
          ]
        }
      ],
      "source": [
        "MnistHistory = MnistModel.fit(\n",
        "    datagen.flow(xTrainMnist, yTrainMnist, batch_size=128), \n",
        "    epochs=1000, \n",
        "    validation_data=(xValidMnist, yValidMnist), \n",
        "    callbacks=[CBCheckPoint], \n",
        "    verbose=2, \n",
        "    steps_per_epoch=xTrainMnist.shape[0] // 128\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### lets see accuracy of the Mnist model : \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "assure the 4 dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xTestMnist = np.expand_dims(xTestMnist, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Evaluate the model on the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 7s 22ms/step - loss: 10.3916 - accuracy: 0.1135\n",
            "Pérdida en el conjunto de prueba: 1039.16%\n",
            "Precisión en el conjunto de prueba: 11.35%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = MnistModel.evaluate(xTestMnist, yTestMnist)\n",
        "print(f\"Pérdida en el conjunto de prueba: {loss * 100:.2f}%\")\n",
        "print(f\"Precisión en el conjunto de prueba: {acc* 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " error  of the model : 1039.16%\n"
          ]
        }
      ],
      "source": [
        "plt.plot(MnistHistory.history['loss'], label='Loss (TRAIN)')\n",
        "plt.plot(MnistHistory.history['val_loss'], label='Loss (VALIDATION)')\n",
        "plt.xlabel('EPOCHS')\n",
        "plt.ylabel('LOSS')\n",
        "plt.title('Loss per epoch')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "print(f\" error  of the model : {loss*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy of the model : 11.35%\n"
          ]
        }
      ],
      "source": [
        "plt.plot(MnistHistory.history['accuracy'], label='accuracy (TRAIN)')\n",
        "plt.plot(MnistHistory.history['val_accuracy'], label='accuracy (VALIDATION)')\n",
        "plt.xlabel('EPOCHS')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('accuracy per epoch')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "print(f\"accuracy of the model : {acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## proceed with a class prediciton for our random sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "use a random variable to our data sample "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "id = np.random.choice(xTestMnist.shape[0], 1000, replace=False) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ],
      "source": [
        "MnistPredictions = MnistModel.predict(xTestMnist[id[0]:id[0]+1]) # make predictions on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted class: [1]\n",
            "rial class:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "predicted_class = np.argmax(MnistPredictions, axis=1)\n",
        "plt.imshow(xTestMnist[id[0]])\n",
        "\n",
        "print(\"predicted class:\" , predicted_class)\n",
        "print(\"rial class: \",yTestMnist[id[0]]) # display the true class of the image"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "icrGGZQg7Kb1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cnnDvlEnv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
